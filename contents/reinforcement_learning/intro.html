

<!DOCTYPE html>


<html lang="es" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>20. Introducción a Aprendizaje Reforzado &#8212; Aprendizaje de Máquinas</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/reinforcement_learning/intro';</script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="21. Entrenando un agente" href="qlearning.html" />
    <link rel="prev" title="19. Consejos para entrenar redes neuronales" href="../neural_networks/tips.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="es"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Saltar al contenido principal</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje Supervisado</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/intro.html">1. Fundamentos de Aprendizaje Supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/linear.html">2. Regresión Lineal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/validation.html">3. Sobreajuste, Validación y Regularización</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/logistic.html">4. Regresión Logística</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/metrics.html">5. Evaluación de clasificadores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/svm.html">6. Máquinas de soporte vectorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/trees.html">7. Árboles de decisión</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/ensembles1.html">8. Ensambles paralelos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/ensembles2.html">9. Ensambles secuenciales</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/features.html">10. Ingeniería de características</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning/engineering.html">11. Machine Learning Engineering (MLE)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Redes Neuronales Artificiales</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/torch-tensor.html">12. Introducción a la librería PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/torch-training.html">13. Entrenamiento de redes neuronales con PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/images.html">14. Introducción al procesamiento digital de imágenes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/cnn.html">15. Red Convolucional en PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/cnn-lightning.html">16. Red Convolucional con Pytorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/data_augmentation.html">17. Aumentación de datos con <code class="docutils literal notranslate"><span class="pre">torchvision</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/transfer_learning.html">18. Utilizando un modelo pre-entrenado</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neural_networks/tips.html">19. Consejos para entrenar redes neuronales</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje Reforzado</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">20. Introducción a Aprendizaje Reforzado</a></li>
<li class="toctree-l1"><a class="reference internal" href="qlearning.html">21. Entrenando un agente</a></li>
<li class="toctree-l1"><a class="reference internal" href="qlearning2.html">22. Q-learning con estado continuo</a></li>
<li class="toctree-l1"><a class="reference internal" href="dqn1.html">23. <em>Deep Reinforced Learning</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="dqn2.html">24. DQN a partir de píxeles</a></li>
<li class="toctree-l1"><a class="reference internal" href="policygrad.html">25. Policy gradients</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/phuijse/MachineLearningBook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Repositorio de origen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/phuijse/MachineLearningBook/issues/new?title=Issue%20on%20page%20%2Fcontents/reinforcement_learning/intro.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Abrir un problema"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Descarga esta pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/contents/reinforcement_learning/intro.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Descargar archivo fuente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Imprimir en PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modo de pantalla completa"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="claro/oscuro" aria-label="claro/oscuro" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introducción a Aprendizaje Reforzado</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenido </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#los-paradigmas-de-aprendizaje-de-maquinas">20.1. Los paradigmas de aprendizaje de máquinas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-de-aprendizaje-reforzado">20.2. Componentes de Aprendizaje Reforzado</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduccion-a-aprendizaje-reforzado">
<h1><span class="section-number">20. </span>Introducción a Aprendizaje Reforzado<a class="headerlink" href="#introduccion-a-aprendizaje-reforzado" title="Permalink to this heading">#</a></h1>
<section id="los-paradigmas-de-aprendizaje-de-maquinas">
<h2><span class="section-number">20.1. </span>Los paradigmas de aprendizaje de máquinas<a class="headerlink" href="#los-paradigmas-de-aprendizaje-de-maquinas" title="Permalink to this heading">#</a></h2>
<div class="admonition-aprendizaje-supervisado admonition">
<p class="admonition-title"><strong>Aprendizaje Supervisado</strong></p>
<p>Tenemos un dataset de <strong>ejemplos etiquetados</strong> <span class="math notranslate nohighlight">\((x, y)\)</span> y buscamos una relación <span class="math notranslate nohighlight">\(f: x \to y\)</span>, es decir predecir <span class="math notranslate nohighlight">\(y\)</span> dado <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div>
<p>Los modelos de regresión y clasificación son ejemplos de este paradigma. En regresión la etiqueta es una variable ordinal mientras que en clasificación la etiqueta es una variable categórica. Si el modelo es paramétrico lo ajustamos (aprendemos sus parámetros) minimizando una función de costo. Por ejemplo, el regresor logístico</p>
<div class="math notranslate nohighlight">
\[
f_\theta = \theta_0 + \sum_{j=1}^D \theta_j x_j
\]</div>
<p>se ajusta minimizando la entropía cruzada:</p>
<div class="math notranslate nohighlight">
\[
\min_{\theta} \sum_{i=1}^N y_i \log \left (f_\theta (x_i) \right)
\]</div>
<a class="reference internal image-reference" href="../../_images/intro-ml1.png"><img alt="../../_images/intro-ml1.png" src="../../_images/intro-ml1.png" style="width: 600px;" /></a>
<div class="admonition-aprendizaje-supervisado admonition">
<p class="admonition-title"><strong>Aprendizaje Supervisado</strong></p>
<p>Tenemos un dataset de <strong>ejemplos sin etiqueta</strong> <span class="math notranslate nohighlight">\((x)\)</span> y buscamos una representación de los datos con ciertas características.</p>
</div>
<p>Los métodos de reducción de dimensionalidad y agrupamiento (clustering) son ejemplos de este paradigma. Por ejemplo, el método de K-Means busca un conjunto de <span class="math notranslate nohighlight">\(K\)</span> representantes (centroides) <span class="math notranslate nohighlight">\(\mu_j\)</span> que resumen el dataset completo en base a la relación de similitud entre los datos:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\min  \sum_{i=1}^N \sum_{k=1}^K w_{ik} \|x_i - \mu_k\|^2 \quad w_{ik} = \begin{cases} 1 &amp; k = \text{arg}\min_j \| x_i - \mu_j\|^2 \\ 0 &amp; \sim \end{cases} 
\end{split}\]</div>
<a class="reference internal image-reference" href="../../_images/intro-ml2.png"><img alt="../../_images/intro-ml2.png" src="../../_images/intro-ml2.png" style="width: 400px;" /></a>
<p><strong>Aprendizaje Reforzado (RL):</strong></p>
<p>El problema fundamental de RL es</p>
<blockquote>
<div><p><strong>aprender</strong> a un sistema que toma la mejor <strong>decisión</strong> en un <strong>ambiente</strong> cambiante</p>
</div></blockquote>
<p>¿Quién toma las decisiones?</p>
<blockquote>
<div><p>El sistema que toma las decisiones e interactua con el ambiente se llama <strong>agente</strong></p>
</div></blockquote>
<p>¿Cómo se cual es la mejor decisión?</p>
<blockquote>
<div><p>La mejor decisión es aquella que obtiene mayor <strong>recompensa</strong></p>
</div></blockquote>
<a class="reference internal image-reference" href="../../_images/intro-ml3.png"><img alt="../../_images/intro-ml3.png" src="../../_images/intro-ml3.png" style="width: 400px;" /></a>
<p>Esto supone diferencias importantes con los paradigmas anteriores. A continuación se definen los componentes de RL resaltando estas diferencias.</p>
</section>
<section id="componentes-de-aprendizaje-reforzado">
<h2><span class="section-number">20.2. </span>Componentes de Aprendizaje Reforzado<a class="headerlink" href="#componentes-de-aprendizaje-reforzado" title="Permalink to this heading">#</a></h2>
<p>El siguiente diagrama (Sutton &amp; Barto, Fig 3.1) muestra como interactuan los componentes principales de RL:</p>
<a class="reference internal image-reference" href="../../_images/intro-rl1.png"><img alt="../../_images/intro-rl1.png" src="../../_images/intro-rl1.png" style="width: 600px;" /></a>
<dl class="simple myst">
<dt>Ambiente (Environment) y Estado (State)</dt><dd><p>En RL, en lugar de ejemplos existe un <strong>ambiente</strong> el cual podemos observar. La percepción del ambiente no siempre es completa. El ambiente se representa por un vector denominado <strong>estado</strong>.</p>
</dd>
<dt>Acciones (Actions)</dt><dd><p>El agente no retorna predicciones sino que toma <strong>decisiones</strong>. En cada instante el agente escoge y realiza una <strong>acción</strong>. Las acciones realizadas pueden modificar el ambiente, es decir que tienen consecuencias.</p>
</dd>
<dt>Recompensa (Reward)</dt><dd><p>La retroalimentación del agente no proviene de etiquetas sino de una señal numérica escalar llamada <strong>recompensa</strong>. Típicamente, la recompensa está asociada a llegar a uno o más estados.</p>
</dd>
</dl>
<p><strong>Características de RL</strong></p>
<ul class="simple">
<li><p>Supervisión: Al agente no se le dice que acción es buena, sino que estados son buenos.</p></li>
<li><p>Prueba y error: El agente debe descubrir que acción le entrega la mayor recompensa probándolas una a una.</p></li>
<li><p>Temporalidad: El entrenamiento y la ejecución son secuenciales, no se puede asumir independiencia.</p></li>
<li><p>Retraso en la retroalimentación: Las recompensas pueden demorar en llegar, las acciones pueden no traer recompensa inmediata pero si en el futuro.</p></li>
</ul>
<p><strong>Objetivo del agente</strong></p>
<p>El agente busca seleccionar acciones para maximizar la <strong>recompensa acumulada futura</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>En ciertos casos podría ser mejor abandonar una recompensa intermedia en pos de obtener una mayor recompensa final</p>
</div>
<p><strong>Hipótesis de recompensa</strong></p>
<p>Todo objetivo puede ser representado mediante la maximización de la recompensa acumulada esperada.</p>
<p><strong>Ciclo de vida de un agente</strong></p>
<p>En general se asume que el tiempo es discreto. La vida del agente se resume en el diagrama anterior, es decir que, en cada tiempo instante <span class="math notranslate nohighlight">\(t\)</span> el agente:</p>
<ol class="arabic simple">
<li><p><strong>recibe recompensa del ambiente:</strong> <span class="math notranslate nohighlight">\(R_t\)</span></p></li>
<li><p><strong>observa el ambiente:</strong> <span class="math notranslate nohighlight">\(S_t\)</span></p></li>
<li><p><strong>realiza una acción:</strong> <span class="math notranslate nohighlight">\(A_t\)</span></p></li>
</ol>
<p>o en pseudo-código</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>for t in 1, 2, 3, ...
    get Rt
    get St
    do At
</pre></div>
</div>
<p>Luego la <strong>historia</strong> de un agente se puede definir como la siguiente trayectoria:</p>
<div class="math notranslate nohighlight">
\[
H_t = ((S_0, A_0), (R_1, S_1, A_1), \ldots, (R_{t-1}, S_{t-1}, A_{t-1}), (R_t, S_t, A_t))
\]</div>
<p><strong>Discusión</strong></p>
<p>¿Puedes reconocer los agentes, las acciones, el ambiente, la recompensa y demás elementos de RL en los siguientes ejemplos?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;Ev0wpVB7OEs&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="800"
            height="400"
            src="https://www.youtube.com/embed/Ev0wpVB7OEs"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;lpi19vExbzc&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="800"
            height="400"
            src="https://www.youtube.com/embed/lpi19vExbzc"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
<p>Reflexione ¿Cuáles son las complejidades de RL en el mundo real?</p>
<blockquote>
<div><p>Phil prepara su desayuno. Si se examina de cerca, incluso esta aparentemente mundana actividad revela una compleja red de comportamiento condicional y relaciones interconectadas de metas y submetas: caminar hacia el armario, abrirlo, seleccionar una caja de cereal y luego alcanzar, agarrar y recuperar la caja. Otros complejos y ajustados secuencias interactivas de comportamiento son necesarias para obtener un tazón, una cuchara y un cartón de leche. Cada paso implica una serie de movimientos oculares para obtener información y guiar el alcance y la locomoción. Se realizan juicios rápidos continuamente sobre cómo llevar los objetos o si es mejor transportar algunos de ellos a la mesa antes de obtener otros. Cada paso está guiado por metas, como agarrar una cuchara o llegar al refrigerador, y está al servicio de otras metas, como tener la cuchara para comer una vez que se haya preparado el cereal y, en última instancia, obtener alimentación. Ya sea consciente o no, Phil está accediendo a información sobre el estado de su cuerpo que determina sus necesidades nutricionales, nivel de hambre y preferencias alimenticias.</p>
<p>Traducción. Original en la Sección 1.2 de Sutton &amp; Barto</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;E2evC2xTNWg&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="800"
            height="400"
            src="https://www.youtube.com/embed/E2evC2xTNWg"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;qBZPSTR96N4&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="800"
            height="400"
            src="https://www.youtube.com/embed/qBZPSTR96N4"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
<p>En el video anterior se muestra el <a class="reference external" href="https://ieeexplore.ieee.org/document/4543527">robot PR1</a> haciendo todo tipo de tareas domésticas. Sin embargo el video es un montaje, ya que PR1 está siendo operado remotamente por un humano.</p>
<blockquote>
<div><p>La habilidad motriz ya es suficiente, el desafio pendiente está en los algoritmos.</p>
</div></blockquote>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents/reinforcement_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../neural_networks/tips.html"
       title="página anterior">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">anterior</p>
        <p class="prev-next-title"><span class="section-number">19. </span>Consejos para entrenar redes neuronales</p>
      </div>
    </a>
    <a class="right-next"
       href="qlearning.html"
       title="siguiente página">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title"><span class="section-number">21. </span>Entrenando un agente</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenido
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#los-paradigmas-de-aprendizaje-de-maquinas">20.1. Los paradigmas de aprendizaje de máquinas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-de-aprendizaje-reforzado">20.2. Componentes de Aprendizaje Reforzado</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Por Pablo Huijse Heise
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>