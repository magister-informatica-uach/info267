
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>10. Machine Learning Engineering (MLE) &#8212; Aprendizaje de Máquinas</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="prev" title="9. Ensambles secuenciales" href="ensembles2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Aprendizaje de Máquinas</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar este libro ..." aria-label="Buscar este libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje Supervisado
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   1. Fundamentos de Aprendizaje Supervisado
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear.html">
   2. Regresión Lineal
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="validation.html">
   3. Sobreajuste, Validación y Regularización
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic.html">
   4. Regresión Logística
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="metrics.html">
   5. Evaluación de clasificadores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svm.html">
   6. Máquinas de soporte vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees.html">
   7. Árboles de decisión
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensembles1.html">
   8. Ensambles paralelos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensembles2.html">
   9. Ensambles secuenciales
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   10. Machine Learning Engineering (MLE)
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navegación de palanca" aria-controls="site-navigation"
                title="Navegación de palanca" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Descarga esta pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/contents/supervised_learning/engineering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Descargar archivo fuente" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimir en PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phuijse/MachineLearningBook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repositorio de origen"><i
                    class="fab fa-github"></i>repositorio</button></a>
        <a class="issues-button"
            href="https://github.com/phuijse/MachineLearningBook/issues/new?title=Issue%20on%20page%20%2Fcontents/supervised_learning/engineering.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Abrir un problema"><i class="fas fa-lightbulb"></i>Tema abierto</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modo de pantalla completa"
        title="Modo de pantalla completa"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phuijse/MachineLearningBook/master?urlpath=tree/contents/supervised_learning/engineering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Lanzamiento Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenido
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ciclo-de-vida-de-un-proyecto-de-ml">
   10.1. Ciclo de vida de un proyecto de ML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recoleccion-y-preparacion-de-datos">
   10.2. Recolección y preparación de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ingenieria-de-caracteristicas">
   10.3. Ingeniería de características
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seleccion-de-caracteristicas">
     10.3.1. Selección de características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#escalamiento-y-normalizacion-de-caracteristicas">
     10.3.2. Escalamiento y normalización de características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduccion-de-dimensionalidad">
     10.3.3. Reducción de dimensionalidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-de-mlops">
   10.4. Herramientas de MLOps
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Machine Learning Engineering (MLE)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contenido </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ciclo-de-vida-de-un-proyecto-de-ml">
   10.1. Ciclo de vida de un proyecto de ML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recoleccion-y-preparacion-de-datos">
   10.2. Recolección y preparación de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ingenieria-de-caracteristicas">
   10.3. Ingeniería de características
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seleccion-de-caracteristicas">
     10.3.1. Selección de características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#escalamiento-y-normalizacion-de-caracteristicas">
     10.3.2. Escalamiento y normalización de características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduccion-de-dimensionalidad">
     10.3.3. Reducción de dimensionalidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-de-mlops">
   10.4. Herramientas de MLOps
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="machine-learning-engineering-mle">
<h1><span class="section-number">10. </span>Machine Learning Engineering (MLE)<a class="headerlink" href="#machine-learning-engineering-mle" title="Enlazar permanentemente con este título">¶</a></h1>
<p><a class="reference external" href="http://mlebook.com/">MLE</a> se refiere al diseño y construcción de software que incluye componentes basados en modelos de Machine Learning (ML). En este sentido, MLE se puede considerar como una extensión de la <a class="reference external" href="https://es.wikipedia.org/wiki/Ingenier%C3%ADa_de_software">ingeniería de software</a> tradicional</p>
<p>Hasta ahora nos hemos concentrado en presentar los aspectos más científicos de como entrenar y evaluar modelos de ML. MLE concierne no sólo el entrenamiento sino también aspectos relacionados a la colección y corrección de datos y al monitoreo y mantenimiendo de los modelos</p>
<div class="section" id="ciclo-de-vida-de-un-proyecto-de-ml">
<h2><span class="section-number">10.1. </span>Ciclo de vida de un proyecto de ML<a class="headerlink" href="#ciclo-de-vida-de-un-proyecto-de-ml" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Las tareas para desarrollar un sofware que utiliza ML pueden dividirse en</p>
<ol class="simple">
<li><p>Recolección y preparación de datos</p></li>
<li><p>Ingeniería de <em>features</em> (características)</p></li>
<li><p>Entrenamiento de modelos</p></li>
<li><p>Evaluación de modelos</p></li>
<li><p>Deployment de modelos</p></li>
<li><p>Servir modelos</p></li>
<li><p>Monitoreo de modelos</p></li>
<li><p>Mantenimiento de modelos</p></li>
</ol>
<p>Donde además se asume como “paso 0” la definición de uno o más objetivos, que vienen a ser los requisitos del software</p>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>El objetivo debe definir las entradas y salidas del modelo. El objetivo también debe definir el criterio o métrica con la que se medirá que tan exitoso es el modelo</p>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>El movimiento entre los pasos anteriores puede ser “hacia atrás”, por ejemplo ante una mala evaluación del modelo o errores detectados en el monitoreo, podríamos retroceder a recolectar nuevos datos y reetrenar el modelo</p>
</div>
<p>Los pasos 3 y 4 han sido revisados en detalle para diversos modelos (regresión logística, SVM, árboles, etc). A continuación revisaremos los demás pasos del flujo anterior. Pero antes respondamos la siguiente pregunta:</p>
<p><strong>¿Cuándo incorporar ML en mi software?</strong></p>
<p>ML provee herramientas para aprender modelos de predicción automáticamente a partir de datos. Antes de implementar corresponde preguntar si:</p>
<ul class="simple">
<li><p>El problema no puede resolverse en base a heurísticas o reglas que puedan programarse “a mano” (o se necesita una cantidad de reglas demasiado grande)</p></li>
<li><p>El costo (monetario o horas humanas) de obtener y etiquetar los datos necesarios no es demasiado alto</p></li>
<li><p>El problema tiene un objetivo simple y bien específicado</p></li>
<li><p>El problema puede admitir algunas respuestas erróneas (accuracy no necesita ser 100%)</p></li>
</ul>
<p>Si alguna de las anteriores no se cumple, deberíamos cuestionar el uso de ML en nuestro sofware</p>
<p>Otro indicio importante es si el problema en cuestion está relacionado a percepción humana, por ejemplo reconocimiento de patrones en imágenes (visión) o sonido (audición). En esos casos ML es en general la mejor solución</p>
</div>
<div class="section" id="recoleccion-y-preparacion-de-datos">
<h2><span class="section-number">10.2. </span>Recolección y preparación de datos<a class="headerlink" href="#recoleccion-y-preparacion-de-datos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Antes de entrenar un modelo se necesitan datos. Antes de iniciar una campaña de recolección de datos que permitan cumplir el objetivo deberíamos investigar si:</p>
<ul class="simple">
<li><p>hay datos existentes que pueden utilizarse</p></li>
<li><p>los datos son suficientes para todas las clases/eventos de interés</p></li>
<li><p>los datos son relativamente actuales (no están obsoletos)</p></li>
<li><p>los datos tienen calidad suficiente</p></li>
</ul>
<p>Los problemas típicamente encontrados en datasets de baja calidad son:</p>
<ul class="simple">
<li><p>Ruido en los datos</p></li>
<li><p>Ruido en las etiquetas: Etiquetadores inconsistentes</p></li>
<li><p>Datos faltantes (<em>missing data</em>)</p></li>
<li><p>Sesgos de selección, muestreo, variables omitidas, etc</p></li>
<li><p>Presencia de <em>outliers</em>: Ejemplos muy alejados de la distribución que pueden afectar el entrenamiento</p></li>
<li><p><em>data leakage</em>: La variable objetivo (etiqueta) está oculta en alguna de las variables</p></li>
</ul>
<p>Algunos de estos problemas puede resolverse mediante</p>
<ul class="simple">
<li><p>Adecuado particionamiento de los datos</p></li>
<li><p>Inputación: Se refiere a rellenar datos faltantes utilizando reglas simples</p></li>
<li><p>Balanceo de clases mediante submuestreo (aleatorio o clustering), sobremuestreo (repetición) o aumentación sintética (por ejemplo <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html">SMOTE</a>)</p></li>
<li><p>Aumentación: Se refiere a crear sintéticamente nuevos datos basados en los existentes</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>Para trabajar con datos desbalanceados utilizando los esquemas mencionados sugiero la librería <a class="reference external" href="https://imbalanced-learn.org/stable/index.html">imbalanced-learn</a></p>
</div>
<p>Si no podemos resolver el problema usando estas técnicas sería necesario recolectar datos propios o re-etiquetar los datos existentes</p>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>Para etiquetar datos de series de tiempo, texto, audio, imágenes de forma  colaborativa y organizanda recomiendo el software <a class="reference external" href="https://labelstud.io/">LabelStudio</a></p>
</div>
<p>Si los datos cambian con cierta frecuencia, viven en distintos servidores y/o necesitan ser compartidos y coordinados en un equipo conviene utilizar <strong>versionamiento</strong></p>
<p>El versionamiento de datos es un concepto reciente, muy similar al versionamiento de código:</p>
<ul class="simple">
<li><p>Cada cambio en nuestros datos es anotado mediante un <em>commit</em></p></li>
<li><p>Los cambios hechos por distintas personas pueden coordinarse de forma centralizada</p></li>
<li><p>Se puede revisar fácilmente la historia de cambios y retroceder a un cambio anterior si es necesario</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>Para realizar versionanamiento de datos sugiero la <a class="reference external" href="https://dvc.org/">Data Version Control</a> (DVC), la cual está basada en git</p>
</div>
</div>
<div class="section" id="ingenieria-de-caracteristicas">
<h2><span class="section-number">10.3. </span>Ingeniería de características<a class="headerlink" href="#ingenieria-de-caracteristicas" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Es muy común que los datos recolectados para resolver un problema de ML no estén originalmente en formato o tipo compatible con el modelo de aprendizaje. Por ejemplo, la mayoría de los métodos que hemos visto en este curso requieren una entrada numérica</p>
<p><strong>Ejemplo</strong> Supongamos que tenemos un dataset de helados y uno de sus atributos es la marca de la empresa que produce el helado: Savory, Bresler, Panda.</p>
<p>Si queremos utilizar la marca como una entrada a un modelo predictivo podríamos codificar estas categorías como numéros enteros utilizando <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html"><code class="docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>

<span class="n">marcas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Savory&#39;</span><span class="p">,</span> <span class="s1">&#39;Bresler&#39;</span><span class="p">,</span> <span class="s1">&#39;Panda&#39;</span><span class="p">])</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">marcas</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[2.],
       [0.],
       [1.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">enc</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&#39;Bresler&#39;]], dtype=&#39;&lt;U7&#39;)
</pre></div>
</div>
</div>
</div>
<div class="admonition error">
<p class="admonition-title">Error</p>
<p>Esta forma ingenua de codificar las categorías introduce una relación de orden ficticia que el modelo podría aprender</p>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Si el número de categorías no es grande, podemos codificarlas sin caer en una relación de orden utilizando one-hot encoding</p>
</div>
<p>Podemos implementar esta codificación con <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder"><code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">marcas</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0., 0., 1.],
       [1., 0., 0.],
       [0., 1., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">enc</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&#39;Savory&#39;]], dtype=&#39;&lt;U7&#39;)
</pre></div>
</div>
</div>
</div>
<p>donde todas las categorías están a una misma distancia de las demás. Esta secuencia de tres números puede ingresar como entrada al modelo</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>En problemas con muchas categorías estaríamos creando vectores de gran tamaño. Un solución típica es agrupar las categorías minoritarias. Esto se puede hacer con <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> utilizando el argumento <code class="docutils literal notranslate"><span class="pre">max_categories</span></code></p>
</div>
<p>Más en general, podemos definir:</p>
<dl class="simple myst">
<dt>Característica (feature)</dt><dd><p>Se refiere a una cantidad obtenida de codificar o transformar los datos (crudos) que puede usarse como entrada de un modelo.</p>
</dd>
<dt>Ingeniería de características (feature engineering)</dt><dd><p>Se refiere a los criterios y procesos para diseñar y obtener características a partir de datos crudos</p>
</dd>
</dl>
<p>Una característica “ideal” debería cumplir con lo siguiente</p>
<ul class="simple">
<li><p>Alto poder predictor: La característica debe estar altamente relacionada con la variable a predecir (etiqueta)</p></li>
<li><p>Baja correlación con otras características: La característica no debe proveer información que esté en otras características</p></li>
<li><p>Alta confianza: La característica debe calcularse a partir de datos que son confiables y representativos del problema</p></li>
<li><p>Rápida de calcular: El cálculo de la característica no debería introducir un <em>overhead</em> computacional que vuelva infactible resolver el problema</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>La ingeniería de características es un proceso creativo que requiere de un acercamiento importante al problema que se quiere resolver</p>
</div>
<p><strong>Discusión:</strong> Un médico quiere predecir <a class="reference external" href="https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data">cancer a partir de una biopsia</a>. El médico resuelve esta tarea observando el tamaño de ciertas células que se caracterisan por su color distintivo ¿Qué características diseñar para este problema?</p>
<p>Si en un problema particular los datos corresponden a los siguientes tipos, podemos considerar las siguientes representaciones para obtener características:</p>
<ul class="simple">
<li><p>Textos: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html">Modelos de tópicos</a> (LDA), Bag of Words, Word2Vec</p></li>
<li><p>Audio: <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html">Espectrogramas</a>, <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.cwt.html">Wavelets</a></p></li>
<li><p>Imágenes: <a class="reference external" href="https://scikit-image.org/">Filtros de extracción de contornos, Gradientes de color, matching de geométrias</a>,</p></li>
<li><p>Series de tiempo: <a class="reference external" href="https://www.sktime.org/en/stable/">Modelos autoregresivos</a></p></li>
</ul>
<p>Ejemplo de características para un dominio particular: <a class="reference external" href="http://isadoranun.github.io/tsfeat/FeaturesDocumentation.html">astronomía</a></p>
<div class="section" id="seleccion-de-caracteristicas">
<h3><span class="section-number">10.3.1. </span>Selección de características<a class="headerlink" href="#seleccion-de-caracteristicas" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Los métodos de selección de características buscan encontrar el subconjunto de características más relevantes para resolver el problema (clasificación o regresión). En el caso más general estos métodos suelen distinguir entre:</p>
<dl class="simple myst">
<dt>Características relevante</dt><dd><p>Es una características que tiene alto poder predictivo, es decir una relación (lineal o no lineal) fuerte con la variable a predecir (etiqueta)</p>
</dd>
<dt>Características complementarias o sinérgicas</dt><dd><p>Son tuplas de características que por si sola tienen bajo poder predictivo, pero estándo juntas tienen alto poder predictivo</p>
</dd>
<dt>Característica redundante</dt><dd><p>Es una característica que si se elimina no afecta el desempeño pues su relación con la etiqueta ya está bien representada por otras variables</p>
</dd>
<dt>Característica irrelevante</dt><dd><p>Es una característica con relación débil o nula con la etiqueta</p>
</dd>
</dl>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>Un buen método de selección debería preservar las características relevantes/complementarias y descartar las irrevelante/redundantes</p>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Eliminar características de poco poder predictivo puede mejorar el rendimiento del clasificador, especialmente si tenemos muchas características (la maldición de la dimensionalidad)</p>
</div>
<p>El módulo <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection"><code class="docutils literal notranslate"><span class="pre">feature_selection</span></code></a> de Scikit-Learn ofrece algunas alternativas para hacer selección de características. Revisemos primero <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest"><code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code></a>. Este objeto espera una función que mida la relevencia de las características y en base a eso retorna las K características más relevantes.</p>
<p>Una métrica muy utilizada para medir relevancia es la <strong>Información Mutua</strong>, que también está implementada en scikit learn como <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif"><code class="docutils literal notranslate"><span class="pre">mutual_info_classif</span></code></a> y <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection"><code class="docutils literal notranslate"><span class="pre">mutual_info_regression</span></code></a></p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>La Información Mutua (IM) mide la cantidad de información compartida entre una característica y la etiqueta. A diferencia de la correlación, la IM es sensible a relaciones no lineales</p>
</div>
<p>Utilicemos como ejemplo un dataset de clasificación sintético de dos clases con seis características</p>
<ul class="simple">
<li><p>Las primeras dos características son relevantes (informativas)</p></li>
<li><p>Las segundas dos son redundantes con las dos primeras</p></li>
<li><p>Las dos restantes son irrelevantes</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
                           <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>La información mutua es:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">SelectKBest</span>

<span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.066961  , 0.40360162, 0.0787783 , 0.46676115, 0.0506025 ,
       0.        ])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La IM de las variables irrelevantes es practicamente nula</p></li>
<li><p>La IM de las variables informativas y relevantes es similar</p></li>
</ul>
<p>Si utilizamos <code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code> con <span class="math notranslate nohighlight">\(K=3\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_reduced</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">selector</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 27 ms, sys: 3.03 ms, total: 30.1 ms
Wall time: 28.8 ms
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((300, 3), array([&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;], dtype=object))
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>La ventaja de este método para hacer selección de características es que no depende de un modelo de clasificación en particular. Otra ventaja es que es muy eficiente computacionalmente</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>La desventaja de este método es que, al medir la relevancia de las características una por una, no es sensible a relaciones de redundancia y complementariedad</p>
</div>
<p>El problema anterior se puede aliviar utilizando un método de eliminación hacia-atras (<em>backward</em>). Scikit-learn tiene dos objetos para lograr este propósito:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE"><code class="docutils literal notranslate"><span class="pre">RFE</span></code></a> (Recursive feature elimination)</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector"><code class="docutils literal notranslate"><span class="pre">SequentialFeatureSelector(direction='backward')</span></code></a></p></li>
</ul>
<p>Ambos métodos requieren de un estimador (regresor o clasificador) y se utiliza el <em>accuracy</em> en validación cruzada para hacer la selección.</p>
<p>En particular <code class="docutils literal notranslate"><span class="pre">SequentialFeatureSelector</span></code></p>
<ul class="simple">
<li><p>Mide el accuracy utilizando todas las características menos una, para todas las características</p></li>
<li><p>Elimina la característica que produje la menor disminución en <em>accuracy</em></p></li>
<li><p>El procedimiento se repite hasta que cumplir con un número esperado de característas especificado por el argumento <code class="docutils literal notranslate"><span class="pre">n_features_to_select</span></code></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Este tipo de eliminación <em>greedy</em> descartará características redundates y no perderá características que son complementarias, pero tiene un gran costo en comparación a lo que vimos antes</p>
</div>
<p>Por ejemplo, si pedimos tres características:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SequentialFeatureSelector</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SequentialFeatureSelector</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;backward&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                     <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">selector</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 124 ms, sys: 3.47 ms, total: 128 ms
Wall time: 128 ms
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;x0&#39;, &#39;x3&#39;, &#39;x5&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>El método no entrega características redudantes entre si</p>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Los resultados dependen del estimador. Usar un estimador distinto puede cambiar considerablemente el resultado</p>
</div>
</div>
<div class="section" id="escalamiento-y-normalizacion-de-caracteristicas">
<h3><span class="section-number">10.3.2. </span>Escalamiento y normalización de características<a class="headerlink" href="#escalamiento-y-normalizacion-de-caracteristicas" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Existen dos razones importantes por las cuales es interesante escalar las características antes de entrenar un modelo</p>
<ol class="simple">
<li><p>Evitar que una variable domine a las otras sólo por tener valores más grandes</p></li>
<li><p>Evitar inestabilidad numérica en el modelo o en el proceso de optimización del mismo]</p></li>
</ol>
<p>El módulo <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"><code class="docutils literal notranslate"><span class="pre">preprocessing</span></code></a> de Scikit Learn proporciona clases y funciones para realizar distintos tipos de escalamiento, entre ellos</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"><code class="docutils literal notranslate"><span class="pre">StandardScaler(with_mean=True,</span> <span class="pre">with_std=True)</span></code></a>: Equivalente a restar la media y dividir por la desviación estándar</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler"><code class="docutils literal notranslate"><span class="pre">MinMaxScaler()</span></code></a>: Reescala la variable tal que su valor mínimo sea 0 y su valor máximo sea 1</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler"><code class="docutils literal notranslate"><span class="pre">MaxAbsScaler()</span></code></a>: Rescala la variable tal que su valor máximo sea 1 (divide por el máximo absoluto)</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler"><code class="docutils literal notranslate"><span class="pre">RobustScaler()</span></code></a>: Similar a <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> pero utiliza estadísticos robustos ante los valores fuera de rango (outliers)</p></li>
</ul>
<p>Los principales métodos de estas clases son</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit(X)</span></code>: Calcula los estadísticos de la transformación de escalamiento para <code class="docutils literal notranslate"><span class="pre">X</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(X)</span></code> Aplica la transformación a <code class="docutils literal notranslate"><span class="pre">X</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(X)</span></code>: Equivalente a aplicar los dos pasos anteriores al mismo tiempo</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(X)</span></code>: Deshace la transformación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.25250744, 0.83164766],
       [1.        , 0.        ],
       [0.        , 0.60127725],
       [0.2769352 , 0.27293887],
       [0.66305614, 1.        ]])
</pre></div>
</div>
</div>
</div>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>Si entrenas sobre características reescaladas debes guardar los valores de los estadísticos para poder normalizar/reescalar ejemplos futuros</p>
</div>
</div>
<div class="section" id="reduccion-de-dimensionalidad">
<h3><span class="section-number">10.3.3. </span>Reducción de dimensionalidad<a class="headerlink" href="#reduccion-de-dimensionalidad" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Los métodos de reducción de dimensionalidad transforman un conjunto de características (numéricas) en un nuevo conjunto con un número menor de variables. Las nuevas características suelen involucrar transformaciones y combinaciones de las características originales.</p>
<p>Existen métodos supervisados y no supervisados para reducir dimensionalidad. En este último caso no se utiliza información de la etiqueta, y se busca minimizar otro tipo de objetivo. Un ejemplo clásico y ampliamente utilizado es Análisis de Componentes Principales (<em>Principal Component Analysis</em>, PCA)</p>
<p>Como muestra la siguiente figura, PCA aplica una transformación sobre las características originales (izquierda), creando nuevas características que son combinaciones lineales de las originales (derecha)</p>
<a class="reference internal image-reference" href="../../_images/pca1.png"><img alt="../../_images/pca1.png" src="../../_images/pca1.png" style="width: 600px;" /></a>
<p>El objetivo de PCA es <strong>maximizar la varianza de las características</strong> proyectadas en el nuevo espacio.</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>PCA produce una cantidad de características equivalente a las que se tenían originalmente</p>
</div>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>La reducción de dimensionalidad en PCA es manual, es decir el usuario debe decidir cuantas características preservar. Un criterio muy usado es seleccionar la cantidad de características en base a la varianza acumulada que representan</p>
</div>
<p>El módulo <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition"><code class="docutils literal notranslate"><span class="pre">decomposition</span></code></a> de scikit-learn tiene clases y objetos para hacer reducción de dimensionalidad, entre ellos <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA"><code class="docutils literal notranslate"><span class="pre">PCA</span></code></a></p>
<p>El argumento principal de <code class="docutils literal notranslate"><span class="pre">PCA</span></code> es <code class="docutils literal notranslate"><span class="pre">n_components</span></code>, el cual puede ser un entero o un flotante en el rango [0, 1]</p>
<ul class="simple">
<li><p>Si es un entero <span class="math notranslate nohighlight">\(K\)</span> el método se quedará con las <span class="math notranslate nohighlight">\(K\)</span> variables de mayor varianza</p></li>
<li><p>Si es un flotante <span class="math notranslate nohighlight">\(p\)</span> el método se quedará con tantas variables como sea necesario con tal de tener un <span class="math notranslate nohighlight">\(100p\%\)</span>  de la varianza</p></li>
</ul>
<p>Veamos un ejemplo con el famoso dataset <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/iris">Iris</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150, 4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">dim_reducer</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">dim_reducer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">X_reduced</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150, 2)
</pre></div>
</div>
</div>
</div>
<p>De acuerdo a los resultados, dos componentes principales son suficientes para preservar un 95% de la varianza</p>
<p>Los datos en el espacio proyectado son:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">y_</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="n">y_</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Componente principal 1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Componente principal 2&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/engineering_38_0.png" src="../../_images/engineering_38_0.png" />
</div>
</div>
<p>Estos nuevas características parecen suficiente para separar las tres clases</p>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>PCA no utiliza la información de clases para hacer la proyección. No siempre maximizar varianza resultará en mayor separabilidad de clases</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>PCA recibe su nombre debido a que las nuevas características y su varianza están relacionadas a los vectores y valores propios de la matriz de correlación de las características originales. Puedes profundizar sobre este tema leyendo <a class="reference external" href="https://docs.google.com/presentation/d/1YqYy5RTB2PJ6C7syMTZCleZqyc2MJVA2APqdBAIhjBw/edit#slide=id.p">esta presentación</a></p>
</div>
</div>
</div>
<div class="section" id="herramientas-de-mlops">
<h2><span class="section-number">10.4. </span>Herramientas de MLOps<a class="headerlink" href="#herramientas-de-mlops" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Un concepto que se utiliza bastante hoy en día es <a class="reference external" href="https://docs.microsoft.com/es-es/azure/machine-learning/concept-model-management-and-deployment">Machine Learning Operations</a> (MLOPs). MLOps se refiere a la implementación de prácticas de Development Operations (DevOps) en problemas de Machine Learning, entre ellas</p>
<ul class="simple">
<li><p>Integración y Entrega continuas (<a class="reference external" href="https://www.redhat.com/en/topics/devops/what-is-ci-cd">CI/CD</a>)</p></li>
<li><p>Flujos automáticos de trabajo (workflows)</p></li>
<li><p>Control de versiones (códigos pero también datos y modelos)</p></li>
<li><p>Empaquetado de soluciones</p></li>
<li><p>Orquestación de carga de inferencia</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>Para hacer CI/CD con modelos de ML recomiendo <a class="reference external" href="https://cml.dev/">CML</a></p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>Para administrar experimentos de Machine Learning existen herramientas de linea de comando como <a class="reference external" href="https://dvc.org/doc/command-reference/exp"><code class="docutils literal notranslate"><span class="pre">dvc</span> <span class="pre">exp</span></code></a> o dashboards como <a class="reference external" href="https://neptune.ai/product">Neptune</a>, <a class="reference external" href="https://mlflow.org/">MLFlow</a> o <a class="reference external" href="https://www.comet.ml/site/">Comet</a></p>
</div>
<p>MLOps está relacionado a los últimos 4 pasos del esquema MLE, estos eran</p>
<p><strong>Entrega y servicio de modelos</strong></p>
<p>Se refiere a cómo se entrega o sirve el modelo y/o sus predicciones al usuario, por ejemplo</p>
<ul class="simple">
<li><p>Estático: El modelo es parte de un ejecutable que está instalado en la máquina del usuario</p></li>
<li><p>Dinámico (on-premise): El usuario tiene un cliente instalado en su máquina el cual solicita actualizaciones periódicas de los parámetros del modelo (cliente y modelo están separados)</p></li>
<li><p>Dinámico (cloud): El usuario sube los datos a un servidor en la nube y recibe las predicciones</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Los modelos de scikit-learn son amigables con <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html">serialización</a>. El modelo serializado puede ser cargado por un servicio web basado en <a class="reference external" href="https://flask.palletsprojects.com/en/2.1.x/">Flask</a> que luego el cliente accede a través de una API Rest</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p>La herramienta <a class="reference external" href="https://mlem.ai/">MLEM</a> de <a class="reference external" href="http://Iterative.ai">Iterative.ai</a> facilita considerablemente el flujo anterior</p>
</div>
<p><strong>Monitoreo y mantenimiento de modelos</strong></p>
<p>Se refiere a la inspección continua del desempeño del modelo en producción. Sea <span class="math notranslate nohighlight">\(X\)</span> los datos de entrada al modelo e <span class="math notranslate nohighlight">\(Y\)</span> la etiqueta a predecir, se define:</p>
<dl class="simple myst">
<dt>Data drift</dt><dd><p>Situación en que la distribución <span class="math notranslate nohighlight">\(p(X)\)</span> empieza a alejarse de la distribución original que se utilizó para entrenar el modelo. Esto puede deberse a que el problema es no-estacionario o a que hubo sesgo de muestreo al crear el dataset de entrenamiento</p>
</dd>
<dt>Prior probability shift</dt><dd><p>Situación en que la distribución <span class="math notranslate nohighlight">\(p(Y)\)</span> se aleja de la distribución original. Por ejemplo una clase deja de aparecer con tanta frecuencia y otra más originalmente más rara ocurre con mayor frecuencia. En el caso extremo podría aparecer una clase que originalmente no estaba en el dataset de entrenamiento</p>
</dd>
<dt>Concept drift</dt><dd><p>Situación en que la distribución condicional <span class="math notranslate nohighlight">\(p(Y|X)\)</span> cambia con respecto a la original y por lo tanto nuestro mapeo <span class="math notranslate nohighlight">\(Y=f(X)\)</span> pierde validez. Está relacionada a situaciones externas: cambio en la interpretación de la etiqueta, aparición de una clase que no estaba considerada originalmente, pérdida de poder predictivo</p>
</dd>
</dl>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>Los <em>drift</em> puede identificarse comparando la distribución de los nuevos datos y predicciones con las de entrenamiento en base test estadísticos (por ejemplo Chi cuadrado o Kolmogorov-Smirov). En caso de detectar <em>drift</em>, debemos analizar las predicciones, etiquetar y reentrenar el modelo</p>
</div>
<p>Adicional al desempeño, también se debe monitorear</p>
<ul class="simple">
<li><p>La disponibilidad del modelo</p></li>
<li><p>La estabilidad numérica del modelo</p></li>
<li><p>El consumo de recursos de hardware del modelo</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents/supervised_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="ensembles2.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title"><span class="section-number">9. </span>Ensambles secuenciales</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Por Pablo Huijse Heise<br/>
    
        &copy; Derechos de autor 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>