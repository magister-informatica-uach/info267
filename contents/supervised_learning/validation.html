
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Sobreajuste, Validación y Regularización &#8212; Aprendizaje de Máquinas</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="4. Regresión Logística" href="logistic.html" />
    <link rel="prev" title="2. Regresión Lineal" href="linear.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Aprendizaje de Máquinas</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar este libro ..." aria-label="Buscar este libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje Supervisado
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   1. Fundamentos de Aprendizaje Supervisado
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear.html">
   2. Regresión Lineal
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Sobreajuste, Validación y Regularización
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic.html">
   4. Regresión Logística
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="metrics.html">
   5. Evaluación de clasificadores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svm.html">
   6. Máquinas de soporte vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees.html">
   7. Árboles de decisión
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensembles1.html">
   8. Ensambles paralelos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensembles2.html">
   9. Ensambles secuenciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="features.html">
   10. Ingeniería de características
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="engineering.html">
   11. Machine Learning Engineering (MLE)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Redes Neuronales Artificiales
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/pytorch1.html">
   12. Breve tutorial de PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/pytorch2.html">
   13. Entrenamiento de redes neuronales con PyTorch
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navegación de palanca" aria-controls="site-navigation"
                title="Navegación de palanca" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Descarga esta pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/contents/supervised_learning/validation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Descargar archivo fuente" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimir en PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phuijse/MachineLearningBook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repositorio de origen"><i
                    class="fab fa-github"></i>repositorio</button></a>
        <a class="issues-button"
            href="https://github.com/phuijse/MachineLearningBook/issues/new?title=Issue%20on%20page%20%2Fcontents/supervised_learning/validation.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Abrir un problema"><i class="fas fa-lightbulb"></i>Tema abierto</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modo de pantalla completa"
        title="Modo de pantalla completa"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phuijse/MachineLearningBook/master?urlpath=tree/contents/supervised_learning/validation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Lanzamiento Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenido
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estrategias-de-validacion">
   3.1. Estrategias de Validación
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#busqueda-de-hiperparametros-con-scikit-learn">
   3.2. Búsqueda de hiperparámetros con scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularizacion">
   3.3. Regularización
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Sobreajuste, Validación y Regularización</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contenido </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estrategias-de-validacion">
   3.1. Estrategias de Validación
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#busqueda-de-hiperparametros-con-scikit-learn">
   3.2. Búsqueda de hiperparámetros con scikit-learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularizacion">
   3.3. Regularización
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="sobreajuste-validacion-y-regularizacion">
<h1><span class="section-number">3. </span>Sobreajuste, Validación y Regularización<a class="headerlink" href="#sobreajuste-validacion-y-regularizacion" title="Enlazar permanentemente con este título">¶</a></h1>
<p>En el ejemplo del <strong>regresor polinomial</strong> vimos que aumentar el grado del polinomio vuelve más flexible al modelo, es decir que aumenta su capacidad para ajustar los datos</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>La cantidad de parámetros (grados de libertaed) del modelo es un proxy de su complejidad. Un modelo más complejo (más parámetros) es en general más flexible</p>
</div>
<p>Sin embargo, si la flexibilidad es excesiva podríamos aproximar ciertos datos con error cero. Esta situación, en que el modelo “memoriza los datos”, se conoce como <strong>sobreajuste</strong></p>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Un modelo sobreajustado tiende a predecir muy mal datos “que no ha visto”, es decir que pierde capacidad de <strong>generalización</strong></p>
</div>
<p>La siguiente figura esquematiza la relación la complejidad o capacidad de ajustar del modelo</p>
<a class="reference internal image-reference" href="../../_images/overfitting.png"><img alt="../../_images/overfitting.png" src="../../_images/overfitting.png" style="width: 400px;" /></a>
<p>Figura: <a class="reference external" href="https://www.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html">https://www.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html</a></p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>En general, mientras más simple (menos complejo) sea el modelo, menos propenso es a sobreajustarse</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Consejo</p>
<p>Podemos evitar el escenario sobreajustado en modelos complejos utilizando un conjunto de datos de validación o estrategias de regularización</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span><span class="mi">3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="estrategias-de-validacion">
<h2><span class="section-number">3.1. </span>Estrategias de Validación<a class="headerlink" href="#estrategias-de-validacion" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Para combatir el sobreajuste podemos usar <strong>estrategias de validación</strong>, estas se basan en separar el conjunto de datos en dos o más subconjuntos, revisemos dos de ellas</p>
<p><strong>Holdout</strong></p>
<p>Consiste en separar los datos en conjuntos de entrenamiento, validación y prueba:</p>
<ul class="simple">
<li><p>El primero se ocupa para entrenar o ajustar el modelo</p></li>
<li><p>El segundo se utiliza para detectar sobreajuste y calibrar los hiperparámetros del modelo</p></li>
<li><p>El tercero se ocupa para realizar una evaluación final libre de sesgos</p></li>
</ul>
<p>Típicamente, la base de datos se particiona en proporción 80%, 10%, 10% si el dataset es grande o 60%, 20%, 20% si el dataset es pequeño</p>
<p><strong>K-fold</strong></p>
<p>La validación cruzada o K-fold consisten en separar el conjunto en <span class="math notranslate nohighlight">\(K\)</span> particiones y utilizarlas alternadamente para entrenar y validar como muestra el siguiente esquema</p>
<a class="reference internal image-reference" href="../../_images/cv.png"><img alt="../../_images/cv.png" src="../../_images/cv.png" style="width: 400px;" /></a>
<p>El caso extremo se conoce como Leave-one-out (LOO), en que se entrena con todos los datos menos uno <span class="math notranslate nohighlight">\(N\)</span> veces.</p>
<blockquote>
<div><p>Para ambos tipos de validación los conjuntos se seleccionan aleatoriamente. También puede hacerse de forma estratificada, es decir manteniendo la proporción de clases</p>
</div></blockquote>
<p>Podemos separar un conjunto en dos con scikit-learn utilizando:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Entrenamiento&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prueba&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>30 24 6
</pre></div>
</div>
<img alt="../../_images/validation_5_1.png" src="../../_images/validation_5_1.png" />
</div>
</div>
<p>En el ejemplo del regresor polinomial podemos utilizar <strong>validación cruzada</strong> para seleccionar el grado de polinomio óptimo</p>
<p>Para esto utilizarmos la función <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"><code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code></a>. Los argumentos principales de esta función son</p>
<ul class="simple">
<li><p>Un modelo de scikit learn</p></li>
<li><p>Datos</p></li>
<li><p>Etiquetas</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cv</span></code>: La cantidad de particiones (K)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scoring</span></code>: Un objeto <code class="docutils literal notranslate"><span class="pre">scorer</span></code> que implementa una métrica de evaluación</p></li>
</ul>
<p>Podemos crear un objeto <code class="docutils literal notranslate"><span class="pre">scorer</span></code> a partir de una métrica de scikit-learn con</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="n">scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Veamos a continuación como se ocupa <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> con el <code class="docutils literal notranslate"><span class="pre">scorer</span></code> que acabamos de crear</p>
<p>Lo utilizaremos para encontrar el mejor grado del polinomio considerando 5 particiones para la validación cruzada</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">val_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="n">degrees</span><span class="p">:</span>
    <span class="c1"># Modelo con validación</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>    
    <span class="n">val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scorer</span><span class="p">))</span>
    <span class="c1"># Modelo sin validación </span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scorer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">))</span>

<span class="n">score_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">score</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">val_scores</span><span class="p">]</span>
<span class="n">degrees</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">score_mean</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3
</pre></div>
</div>
</div>
</div>
<p>Si visualizamos los resultados:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">score_mean</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">score_mean</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validación&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Entrenamiento&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Grado del polinomio&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Error medio cuadrático&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/validation_11_0.png" src="../../_images/validation_11_0.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>El regresor polinomial con menor error de validación es de grado 3</p>
</div>
<p>En resumen</p>
<ul class="simple">
<li><p>Bajo error de entrenamiento y de validación: <strong>Ideal</strong></p></li>
<li><p>Bajo error de entrenamiento y alto error de validación: <strong>Modelo sobreajustado</strong></p></li>
<li><p>Alto error de entrenamiento y de validación: Considera un modelo de mayor complejidad y asegurate que tu código no tenga bugs</p></li>
</ul>
</div>
<div class="section" id="busqueda-de-hiperparametros-con-scikit-learn">
<h2><span class="section-number">3.2. </span>Búsqueda de hiperparámetros con scikit-learn<a class="headerlink" href="#busqueda-de-hiperparametros-con-scikit-learn" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Podemos automatizar aun más la búsqueda de hiperparámetros utilizando <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a></p>
<p>Los argumentos principales de esta clase son</p>
<ul class="simple">
<li><p>Un estimador (regresor o clasificador) de scikit-learn</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">param_grid</span></code>: Un diccionario con los valores de los hiperparámetros que se han de explorar</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cv</span></code>: La cantidad de particiones para la validación cruzada</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scoring</span></code>: Una métrica que se utilizará para evaluar los modelos</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>: El número de núcleos de CPU</p></li>
</ul>
<p>Para crear el diccionario de parámetros primero necesitamos conocer los nombres de los parámetros de nuestro modelo. Los estimadores de scikit-learn tienen un método <code class="docutils literal notranslate"><span class="pre">get_params()</span></code> que facilita esta tarea</p>
<p>Por ejemplo para el regresor polinomial:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;memory&#39;: None,
 &#39;steps&#39;: [(&#39;polynomialfeatures&#39;, PolynomialFeatures(degree=10)),
  (&#39;linearregression&#39;, LinearRegression(fit_intercept=False))],
 &#39;verbose&#39;: False,
 &#39;polynomialfeatures&#39;: PolynomialFeatures(degree=10),
 &#39;linearregression&#39;: LinearRegression(fit_intercept=False),
 &#39;polynomialfeatures__degree&#39;: 10,
 &#39;polynomialfeatures__include_bias&#39;: True,
 &#39;polynomialfeatures__interaction_only&#39;: False,
 &#39;polynomialfeatures__order&#39;: &#39;C&#39;,
 &#39;linearregression__copy_X&#39;: True,
 &#39;linearregression__fit_intercept&#39;: False,
 &#39;linearregression__n_jobs&#39;: None,
 &#39;linearregression__normalize&#39;: &#39;deprecated&#39;,
 &#39;linearregression__positive&#39;: False}
</pre></div>
</div>
</div>
</div>
<p>Para hacer validación cruzada con el grado del polinomio debemos utilizar <code class="docutils literal notranslate"><span class="pre">polynomialfeatures__degree</span></code></p>
<p>Por ejemplo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;polynomialfeatures__degree&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
<p>Es decir que probaremos los valores <code class="docutils literal notranslate"><span class="pre">degree</span></code> desde 1 a 19</p>
<p>El método principal de <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> es <code class="docutils literal notranslate"><span class="pre">fit(X,</span> <span class="pre">y)</span></code>. Este método realiza la validación cruzada con todas las combinaciones de hiperparámetros especificadas en <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> y retorna la “mejor” según el <code class="docutils literal notranslate"><span class="pre">scorer</span></code> seleccionado</p>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Por convención <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> espera un <code class="docutils literal notranslate"><span class="pre">scorer</span></code> donde valores más grandes se consideran mejores que valores pequeños, es decir que maximiza en lugar de minimizar. Esto no es correcto para el error medio cuadrático</p>
</div>
<p>Utilizando <code class="docutils literal notranslate"><span class="pre">greater_is_better=False</span></code> la métrica se multiplica por <span class="math notranslate nohighlight">\(-1\)</span> y corregimos esa situación</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finalmente hacemos el ajuste con los parámetros y <code class="docutils literal notranslate"><span class="pre">scorer</span></code> escogidos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">validator</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">validator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 19 candidates, totalling 95 fits
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#39;polynomialfeatures&#39;,
                                        PolynomialFeatures(degree=10)),
                                       (&#39;linearregression&#39;,
                                        LinearRegression(fit_intercept=False))]),
             param_grid={&#39;polynomialfeatures__degree&#39;: range(1, 20)},
             scoring=make_scorer(mean_squared_error, greater_is_better=False),
             verbose=True)
</pre></div>
</div>
</div>
</div>
<p>Una vez realizado el ajuste podemos utilizar los principales atributos de la clase:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">best_params_</span></code>: Retorna un diccionario que los hiperparámetros del mejor modelo</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">best_score_</span></code>: Retorna el error del mejor modelo</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>: Retorna el estimador de mejor desempeño en validación</p></li>
</ul>
<p>El mejor resultado en este caso es:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validator</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">validator</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>({&#39;polynomialfeatures__degree&#39;: 3}, -1.5070219734256671)
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p><code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> tiene también los métodos <code class="docutils literal notranslate"><span class="pre">predict</span></code> y <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> (siempre y cuando estos estén implementados en el estimador utilizado). Se retorna la predicción del mejor modelo según la validación cruzada</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">y_range</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_range</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">y_range</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/validation_28_0.png" src="../../_images/validation_28_0.png" />
</div>
</div>
</div>
<div class="section" id="regularizacion">
<h2><span class="section-number">3.3. </span>Regularización<a class="headerlink" href="#regularizacion" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Considere las predicciones de los siguientes modelos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">simple_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_simple</span> <span class="o">=</span> <span class="n">simple_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_range</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">complex_model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">complex_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_complex</span> <span class="o">=</span> <span class="n">complex_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_range</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">y_pred_complex</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Complejo (grado=20)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">y_pred_simple</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Simple (grado=3)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/validation_32_0.png" src="../../_images/validation_32_0.png" />
</div>
</div>
<p>Respecto a un escenario similar al anterior, se enunció lo siguiente:</p>
<blockquote class="epigraph">
<div><p>“en igualdad de condiciones, la explicación más simple suele ser la más probable”
— <a class="reference external" href="https://es.wikipedia.org/wiki/Guillermo_de_Ockham">William de Ockham</a></p>
</div></blockquote>
<p>que se conoce como la navaja de Ockham o el principio de parsimonia.</p>
<p>Aplicando este principio al regresor polinomial llegaríamos a que ante modelos con error comparable deberíamos seleccionar el más simple (o menos complejo)</p>
<blockquote>
<div><p>Esto es la base de la <strong>regularización</strong>, un concepto estadístico que consiste en guiar la optimización de un problema mediante una penalización adicional</p>
</div></blockquote>
<p>En este caso buscamos penalizar la complejidad del modelo. En problemas de regresión y clasificación esto se suele implementar como un término extra en la función de costo.</p>
<p><strong>Regresor lineal regularizado</strong></p>
<p>Podemos regularizar el regresor lineal utilizando la siguiente función de costo:</p>
<div class="math notranslate nohighlight">
\[
L(\theta) = \frac{1}{2} (Y - \Phi \theta)^T (Y - \Phi \theta) + \alpha \theta^T \theta
\]</div>
<p>donde el término de la derecha es la norma euclidiana (L2) del vector de parámetros y <span class="math notranslate nohighlight">\(\alpha\)</span> es un hiperparámetro que controla el peso relativo entre ambos objetivos de optimización.</p>
<div class="admonition important">
<p class="admonition-title">Importante</p>
<p>Cuando regularizamos el regresor lineal buscamos el <span class="math notranslate nohighlight">\(\theta\)</span> de mínimo error y además de mínima norma. La mínima norma euclidiana se puede interpretar como la solución “más suave”</p>
</div>
<p>La solución con la función de costo regularizada es</p>
<div class="math notranslate nohighlight">
\[
\hat \theta = (X^T X + I\alpha)^{-1} X^T Y,
\]</div>
<p>que se conoce como regresión contraida o <em>ridge regression</em></p>
<p>Este modelo está implementado en scikit-learn como <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">Ridge</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1e+5</span><span class="p">]:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> 
                          <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> 
                          <span class="n">Ridge</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_range</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Alpha: </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/validation_35_0.png" src="../../_images/validation_35_0.png" />
</div>
</div>
<p>Mientras mayor sea <span class="math notranslate nohighlight">\(\alpha\)</span>, más suave es el resultado del regresor</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(\alpha=0.0\)</span> sólo optimizamos el error y no la suavidad</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\alpha \to \infty\)</span> entonces sólo optimizamos la suavidad y no el error</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Utilizando <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> calibramos <span class="math notranslate nohighlight">\(\alpha\)</span> en lugar del grado del polinomio. Si los datos están estandarizados <span class="math notranslate nohighlight">\(\alpha=1\)</span> es un buen valor inicial</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1UUpK4zSdzRcS79V7_wU9nXe-sR7qYLEWhbmid-Rfp1k/edit?usp=sharing">Una presentación sobre regresión que incluye métodos que no veremos en este curso</a>. En particular se presenta otro método de regularización popular: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html">LASSO</a></p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents/supervised_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="linear.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title"><span class="section-number">2. </span>Regresión Lineal</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="logistic.html" title="siguiente página">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Regresión Logística</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Por Pablo Huijse Heise<br/>
    
        &copy; Derechos de autor 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>