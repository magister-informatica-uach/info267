{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de Aprendizaje Supervisado\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Dentro del aprendizaje de máquinas (*machine learning*) el aprendizaje **supervisado** es un paradigma o esquema en que se busca obtener una función \n",
    "\n",
    "$$\n",
    "f_{\\theta}: \\mathcal{X} \\rightarrow \\mathcal{Y},\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "- $\\mathcal{X}$ es el dominio de entrada al cual pertenecen nuestros datos o atributos \n",
    "- $\\mathcal{Y}$ el dominio de salida al cual pertenece la variable objetivo que queremos predecir\n",
    "- $\\theta$ es un vector de parámetros de la función o modelo\n",
    "\n",
    "En esta unidad nos concentraremos en dos tipos de problemas o tareas, los cuales se describen a continuación:\n",
    "\n",
    "**Regresión** \n",
    "\n",
    "En esta tarea buscamos un modelo que asocie una entrada de $m$ variables continuas a una salida de una variable continua \n",
    "\n",
    "$$\n",
    "f_{\\theta}: \\mathbb{R}^m \\rightarrow \\mathbb{R}\n",
    "$$ \n",
    "\n",
    "Típicamente se llaman variables independientes a las entradas y variables dependientes a la salida.\n",
    "\n",
    "\n",
    "Algunos ejemplos de problemas de regresión: \n",
    "\n",
    "- [El flujo de tráfico de una calle en función de un feed de video](https://archive.ics.uci.edu/ml/datasets/Traffic+Flow+Forecasting)\n",
    "- [La concentración de un químico aereo en función del valor del mismo en el pasado](https://archive.ics.uci.edu/ml/datasets/air+quality)\n",
    "- [La ocurrencia de una llamarada solar en función del brillo y la cantidad de manchas en la corona del sol](http://archive.ics.uci.edu/ml/datasets/solar+flare)\n",
    "\n",
    "\n",
    "\n",
    "**Clasificación**\n",
    "\n",
    "En esta tarea buscamos un modelo que retorne una entre $K$ categorías para una entidad que se representa por $m$ variables de entrada o atributos.\n",
    "\n",
    "$$\n",
    "f_{\\theta}: \\mathbb{R}^m \\rightarrow \\{1, 2, \\ldots, K\\}\n",
    "$$\n",
    "\n",
    "Algunos ejemplos:\n",
    "\n",
    "- [Identificar si un correo electrónico es *spam* o no en base a descriptores de su contenido y sus metadatos](https://archive.ics.uci.edu/ml/datasets/spambase)\n",
    "- [Diagnóstico benigno o maligno en función de descriptores de las células de una biopsia por sospecha de cancer de mama](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic))\n",
    "- [Identificar la letra correspondiente a una imagen que muestra un gesto de lengua de señas](https://archive.ics.uci.edu/ml/datasets/Australian+Sign+Language+signs+(High+Quality))\n",
    "\n",
    "\n",
    "> ¿Puede reconocer cuales son las clases en cada uno de los problemas anteriores?\n",
    "\n",
    "\n",
    "**Otras tareas que se resuelven con *machine learning***\n",
    "\n",
    "La siguiente lista tiene ejemplos de otras tareas de machine learning, supervisado, no supervisado y semi-supervisado, que no veremos en esta unidad.\n",
    "\n",
    "- Machine Translation: El objetivo es convertir una secuencia de texto de un idioma a otro\n",
    "- Imputación: El objetivo es rellenar valores faltantes en una base de datos\n",
    "- Detección de anomalías: El objetivo es encontrar ejemplos atípicos, es decir que difieren en características al resto de la base de datos\n",
    "- Denoising: El objetivo es retornar una versión de los datos de entrada con menos ruido\n",
    "- Síntesis: El objetivo es generar nuevos ejemplos de texto, audio,  o imágenes que se asemejan a los datos reales\n",
    "- Clustering: El objetivo es agrupar los ejemplos según un criterio de similitud o densidad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos y definiciones \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento**\n",
    "\n",
    "Los problemas de aprendizaje **supervisado** se resuelven \"enseñándole\" al modelo en base a ejemplos donde la respuesta correcta se conoce de antemano. Este proceso se denomina **entrenamiento** o ajuste del modelo. \n",
    "\n",
    "Para entrenar necesitamos entonces un conjunto de $N$ ejemplos:\n",
    "\n",
    "$$\n",
    "\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\},\n",
    "$$\n",
    "\n",
    "donde cada ejemplo es una tupla que contiene \n",
    "\n",
    "- $x_i \\in \\mathcal{X}$: la entrada para el modelo (datos o atributos) \n",
    "- $y_i \\in \\mathcal{Y}$: la salida que el modelo debiera retornar (objetivo) \n",
    "\n",
    ":::{note}\n",
    "\n",
    "En problemas de clasificación, la variable objetivo suele llamarse **etiqueta**. \n",
    "\n",
    ":::\n",
    "\n",
    "En modelos parámetricos como $f_\\theta$, entrenar corresponde a encontrar el valor de $\\theta$ con el cual se obtiene \"el mejor\" mapeo entre entrada y salida.\n",
    "\n",
    "> Para encontrar el mejor debemos definir primero un criterio (función de costo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de costo**\n",
    "\n",
    "La función de costo, también llamada pérdida, mide el error de nuestro modelo sobre un conjunto de datos etiquetados.\n",
    "\n",
    "Por ejemplo, para problemas de regresión, una función de costo muy común es la suma de errores cuadrados\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\sum_{i=1}^N (f_\\theta(x_i) - y_i)^2\n",
    "$$\n",
    "\n",
    "donde mientras más cerca a cero sea $L(\\theta)$, mejor es nuestro modelo (según este criterio).\n",
    "\n",
    "En modelos parámetricos como $f_\\theta$, encontrar el mejor mapeo es equivalente a encontrar el valor de $\\theta$ que minimiza $L(\\theta)$, es decir el $\\theta$ óptimo.\n",
    "\n",
    "> Para encontrar el valor de $\\theta$ que minimiza el criterio necesitamos algoritmos de optimización.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización**\n",
    "\n",
    "Para entrenar el modelo tenemos que resolver el siguiente problema:\n",
    "\n",
    "$$\n",
    "\\min_\\theta L(\\theta)\n",
    "$$\n",
    "\n",
    "Y las opciones que tenemos son:\n",
    "\n",
    "- Evaluar $L()$ con una estrategia de fuerza bruta. Esta opción es en general infactible.\n",
    "- Aplicar técnicas analíticas, por ejemplo resolver $\\nabla_\\theta L(\\theta) = \\vec 0$. Esta opción sólo puede aplicarse en algunos problemas.\n",
    "- Usar técnicas numéricas iterativas, por ejemplo el método de Newton o gradiente descendente. Utilizaremos estas técnicas durante esta unidad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferencia**\n",
    "\n",
    "Luego de entrenar y validar el modelo podemos utilizarlo para hacer inferir la variable objetivo $y^*$ en datos nuevos $x^*$,  es decir fuera de los que se utilizaron para entrenar:\n",
    "\n",
    "$$\n",
    "y^* = f_\\theta(x^*) \n",
    "$$\n",
    "\n",
    ":::{important}\n",
    "\n",
    "Este es el objetivo fundamental de *machine learning*: Aprender modelos complejos a partir de ejemplos para luego aplicarlos automaticamente sobre nuevos datos.\n",
    "\n",
    ":::\n",
    "\n",
    "El siguiente diagrama ejemplifica este proceso y además compara machine learning con la programación tradicional:\n",
    "\n",
    "<img src=\"img/traditional_vs_ml.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generalización**\n",
    "\n",
    "Es la capacidad de un modelo de hacer buenas inferencias en datos que no fueron utilizados para ajustarlo (datos que no ha visto). \n",
    "\n",
    ":::{note}\n",
    "\n",
    "Para medir la capacidad de generalización se suele \"esconder\" una parte del conjunto de entrenamiento. Veremos este tipo de técnicas en detalle más adelante.\n",
    "\n",
    ":::\n",
    "\n",
    "**Representatividad**\n",
    "\n",
    "Es crítico que los datos que utilizemos **representen** adecuadamente el problema que queremos resolver. Idealmente, la distribución de los datos de entrenamiento no debiera diferir demasiado de los datos de prueba.\n",
    "\n",
    "En caso de que esto ocurriera sería necesario reentrenar el modelo con nuevos datos que reflejen este cambio.\n",
    "\n",
    "**Sesgos**\n",
    "\n",
    "Un sesgo es una preferencia generalmente indeseada en un modelo. Muchas veces los sesgos del modelo son sesgos de los datos que utilizamos para entrenar. El más típico es el sesgo causado por clases desbalanceadas o exclusión de clases.\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Sin embargo esto puede ser más grave, por ejemplo sesgos raciales y de género, como muestra [la siguiente breve presentación](https://docs.google.com/presentation/d/1txaRV35N6OOxv4DF4ZIlAFUKty7pBfMu1erLe2k4-Xg/edit#slide=id.g8fcb23695b_1_0).\n",
    "\n",
    ":::\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
