{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe989ea",
   "metadata": {},
   "source": [
    "# Machine Learning Engineering (MLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db854f93",
   "metadata": {},
   "source": [
    "[MLE](http://mlebook.com/) se refiere al diseño y construcción de software que incluye componentes basados en modelos de Machine Learning (ML). En este sentido, MLE se puede considerar como una extensión de la [ingeniería de software](https://es.wikipedia.org/wiki/Ingenier%C3%ADa_de_software) tradicional\n",
    "\n",
    "Hasta ahora nos hemos concentrado en presentar los aspectos más científicos de como entrenar y evaluar modelos de ML. MLE concierne no sólo el entrenamiento sino también aspectos relacionados a la colección y corrección de datos y al monitoreo y mantenimiendo de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec3206",
   "metadata": {},
   "source": [
    "## Ciclo de vida de un proyecto de ML\n",
    "\n",
    "Las tareas para desarrollar un sofware que utiliza ML pueden dividirse en\n",
    "\n",
    "1. Recolección y preparación de datos\n",
    "1. Ingeniería de *features* (características)\n",
    "1. Entrenamiento de modelos\n",
    "1. Evaluación de modelos\n",
    "1. Deployment de modelos\n",
    "1. Servir modelos \n",
    "1. Monitoreo de modelos\n",
    "1. Mantenimiento de modelos\n",
    "\n",
    "Donde además se asume como \"paso 0\" la definición de uno o más objetivos, que vienen a ser los requisitos del software\n",
    "\n",
    ":::{important}\n",
    "\n",
    "El objetivo debe definir las entradas y salidas del modelo. El objetivo también debe definir el criterio o métrica con la que se medirá que tan exitoso es el modelo\n",
    "\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "\n",
    "El movimiento entre los pasos anteriores puede ser \"hacia atrás\", por ejemplo ante una mala evaluación del modelo o errores detectados en el monitoreo, podríamos retroceder a recolectar nuevos datos y reetrenar el modelo\n",
    "\n",
    ":::\n",
    "\n",
    "Los pasos 3 y 4 han sido revisados en detalle para diversos modelos (regresión logística, SVM, árboles, etc). A continuación revisaremos los demás pasos del flujo anterior. Pero antes respondamos la siguiente pregunta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c511615",
   "metadata": {},
   "source": [
    "**¿Cuándo incorporar ML en mi software?**\n",
    "\n",
    "ML provee herramientas para aprender modelos de predicción automáticamente a partir de datos. Antes de implementar corresponde preguntar si:\n",
    "\n",
    "- El problema no puede resolverse en base a heurísticas o reglas que puedan programarse \"a mano\" (o se necesita una cantidad de reglas demasiado grande) \n",
    "- El costo (monetario o horas humanas) de obtener y etiquetar los datos necesarios no es demasiado alto\n",
    "- El problema tiene un objetivo simple y bien específicado\n",
    "- El problema puede admitir algunas respuestas erróneas (accuracy no necesita ser 100%)\n",
    "\n",
    "Si alguna de las anteriores no se cumple, deberíamos cuestionar el uso de ML en nuestro sofware \n",
    "\n",
    "Otro indicio importante es si el problema en cuestion está relacionado a percepción humana, por ejemplo reconocimiento de patrones en imágenes (visión) o sonido (audición). En esos casos ML es en general la mejor solución\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b3dc1",
   "metadata": {},
   "source": [
    "## Recolección y preparación de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349ed1b",
   "metadata": {},
   "source": [
    "Antes de entrenar un modelo se necesitan datos. Antes de iniciar una campaña de recolección de datos que permitan cumplir el objetivo deberíamos investigar si:\n",
    "\n",
    "- hay datos existentes que pueden utilizarse \n",
    "- los datos son suficientes para todas las clases/eventos de interés\n",
    "- los datos son relativamente actuales (no están obsoletos)\n",
    "- los datos tienen calidad suficiente \n",
    "\n",
    "Los problemas típicamente encontrados en datasets de baja calidad son:\n",
    "\n",
    "- Ruido en los datos\n",
    "- Ruido en las etiquetas: Etiquetadores inconsistentes\n",
    "- Datos faltantes (*missing data*)\n",
    "- Sesgos de selección, muestreo, variables omitidas, etc\n",
    "- Presencia de *outliers*: Ejemplos muy alejados de la distribución que pueden afectar el entrenamiento\n",
    "- *data leakage*: La variable objetivo (etiqueta) está oculta en alguna de las variables\n",
    "\n",
    "Algunos de estos problemas puede resolverse mediante\n",
    "\n",
    "- Adecuado particionamiento de los datos\n",
    "- Inputación: Se refiere a rellenar datos faltantes utilizando reglas simples\n",
    "- Balanceo de clases mediante submuestreo (aleatorio o clustering), sobremuestreo (repetición) o aumentación sintética (por ejemplo [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html))\n",
    "- Aumentación: Se refiere a crear sintéticamente nuevos datos basados en los existentes\n",
    "\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Para trabajar con datos desbalanceados utilizando los esquemas mencionados sugiero la librería [imbalanced-learn](https://imbalanced-learn.org/stable/index.html)\n",
    "\n",
    ":::\n",
    "\n",
    "Si no podemos resolver el problema usando estas técnicas sería necesario recolectar datos propios o re-etiquetar los datos existentes\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Para etiquetar datos de series de tiempo, texto, audio, imágenes de forma  colaborativa y organizanda recomiendo el software [LabelStudio](https://labelstud.io/)\n",
    "\n",
    ":::\n",
    "\n",
    "Si los datos cambian con cierta frecuencia, viven en distintos servidores y/o necesitan ser compartidos y coordinados en un equipo conviene utilizar **versionamiento**\n",
    "\n",
    "El versionamiento de datos es un concepto reciente, muy similar al versionamiento de código:\n",
    "\n",
    "- Cada cambio en nuestros datos es anotado mediante un *commit*\n",
    "- Los cambios hechos por distintas personas pueden coordinarse de forma centralizada\n",
    "- Se puede revisar fácilmente la historia de cambios y retroceder a un cambio anterior si es necesario\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Para realizar versionanamiento de datos sugiero la [Data Version Control](https://dvc.org/) (DVC), la cual está basada en git\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f0b06",
   "metadata": {},
   "source": [
    "## Ingeniería de características \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b406a6c",
   "metadata": {},
   "source": [
    "Es muy común que los datos recolectados para resolver un problema de ML no estén originalmente en formato o tipo compatible con el modelo de aprendizaje. Por ejemplo, la mayoría de los métodos que hemos visto en este curso requieren una entrada numérica\n",
    "\n",
    "**Ejemplo** Supongamos que tenemos un dataset de helados y uno de sus atributos es la marca de la empresa que produce el helado: Savory, Bresler, Panda. \n",
    "\n",
    "Si queremos utilizar la marca como una entrada a un modelo predictivo podríamos codificar estas categorías como numéros enteros utilizando [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8df834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "marcas = np.array(['Savory', 'Bresler', 'Panda'])\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit_transform(marcas.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be88c90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Bresler']], dtype='<U7')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed863e6",
   "metadata": {},
   "source": [
    ":::{error}\n",
    "\n",
    "Esta forma ingenua de codificar las categorías introduce una relación de orden ficticia que el modelo podría aprender\n",
    "\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Si el número de categorías no es grande, podemos codificarlas sin caer en una relación de orden utilizando one-hot encoding\n",
    "\n",
    ":::\n",
    "\n",
    "Podemos implementar esta codificación con [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dd4ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit_transform(marcas.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3190e716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Savory']], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform([[0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c7337",
   "metadata": {},
   "source": [
    "donde todas las categorías están a una misma distancia de las demás. Esta secuencia de tres números puede ingresar como entrada al modelo\n",
    "\n",
    ":::{note}\n",
    "\n",
    "En problemas con muchas categorías estaríamos creando vectores de gran tamaño. Un solución típica es agrupar las categorías minoritarias. Esto se puede hacer con `OneHotEncoder` utilizando el argumento `max_categories`\n",
    "\n",
    ":::\n",
    "\n",
    "Más en general, podemos definir:\n",
    "\n",
    "Característica (feature)\n",
    ": Se refiere a una cantidad obtenida de codificar o transformar los datos (crudos) que puede usarse como entrada de un modelo. \n",
    "\n",
    "Ingeniería de características (feature engineering)\n",
    ": Se refiere a los criterios y procesos para diseñar y obtener características a partir de datos crudos\n",
    "\n",
    "Una característica \"ideal\" debería cumplir con lo siguiente\n",
    "\n",
    "- Alto poder predictor: La característica debe estar altamente relacionada con la variable a predecir (etiqueta)\n",
    "- Baja correlación con otras características: La característica no debe proveer información que esté en otras características\n",
    "- Alta confianza: La característica debe calcularse a partir de datos que son confiables y representativos del problema\n",
    "- Rápida de calcular: El cálculo de la característica no debería introducir un *overhead* computacional que vuelva infactible resolver el problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8181ed6",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "\n",
    "La ingeniería de características es un proceso creativo que requiere de un acercamiento importante al problema que se quiere resolver\n",
    "\n",
    ":::\n",
    "\n",
    "**Discusión:** Un médico quiere predecir [cancer a partir de una biopsia](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data). El médico resuelve esta tarea observando el tamaño de ciertas células que se caracterisan por su color distintivo ¿Qué características diseñar para este problema?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62f38b",
   "metadata": {},
   "source": [
    "Si en un problema particular los datos corresponden a los siguientes tipos, podemos considerar las siguientes representaciones para obtener características:\n",
    "\n",
    "- Textos: [Modelos de tópicos](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) (LDA), Bag of Words, Word2Vec\n",
    "- Audio: [Espectrogramas](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html), [Wavelets](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.cwt.html)\n",
    "- Imágenes: [Filtros de extracción de contornos, Gradientes de color, matching de geométrias](https://scikit-image.org/), \n",
    "- Series de tiempo: [Modelos autoregresivos](https://www.sktime.org/en/stable/)\n",
    "\n",
    "Ejemplo de características para un dominio particular: [astronomía](http://isadoranun.github.io/tsfeat/FeaturesDocumentation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86388bf7",
   "metadata": {},
   "source": [
    "### Selección de características\n",
    "\n",
    "Los métodos de selección de características buscan encontrar el subconjunto de características más relevantes para resolver el problema (clasificación o regresión). En el caso más general estos métodos suelen distinguir entre:\n",
    "\n",
    "Características relevante\n",
    ": Es una características que tiene alto poder predictivo, es decir una relación (lineal o no lineal) fuerte con la variable a predecir (etiqueta)\n",
    "\n",
    "Características complementarias o sinérgicas\n",
    ": Son tuplas de características que por si sola tienen bajo poder predictivo, pero estándo juntas tienen alto poder predictivo\n",
    "\n",
    "Característica redundante\n",
    ": Es una característica que si se elimina no afecta el desempeño pues su relación con la etiqueta ya está bien representada por otras variables\n",
    "\n",
    "Característica irrelevante\n",
    ": Es una característica con relación débil o nula con la etiqueta\n",
    "\n",
    ":::{important}\n",
    "\n",
    "Un buen método de selección debería preservar las características relevantes/complementarias y descartar las irrevelante/redundantes\n",
    "\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Eliminar características de poco poder predictivo puede mejorar el rendimiento del clasificador, especialmente si tenemos muchas características (la maldición de la dimensionalidad)\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac54f8",
   "metadata": {},
   "source": [
    "El módulo [`feature_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) de Scikit-Learn ofrece algunas alternativas para hacer selección de características. Revisemos primero [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest). Este objeto espera una función que mida la relevencia de las características y en base a eso retorna las K características más relevantes. \n",
    "\n",
    "Una métrica muy utilizada para medir relevancia es la **Información Mutua**, que también está implementada en scikit learn como [`mutual_info_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif) y [`mutual_info_regression`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)\n",
    "\n",
    ":::{note}\n",
    "\n",
    "La Información Mutua (IM) mide la cantidad de información compartida entre una característica y la etiqueta. A diferencia de la correlación, la IM es sensible a relaciones no lineales\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabff50",
   "metadata": {},
   "source": [
    "Utilicemos como ejemplo un dataset de clasificación sintético de dos clases con seis características\n",
    "\n",
    "- Las primeras dos características son relevantes (informativas)\n",
    "- Las segundas dos son redundantes con las dos primeras \n",
    "- Las dos restantes son irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2a5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_classes=2, n_features=6, \n",
    "                           n_informative=2, n_redundant=2, n_clusters_per_class=1,\n",
    "                           shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f4da5",
   "metadata": {},
   "source": [
    "La información mutua es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580e9474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.066961  , 0.40360162, 0.0787783 , 0.46676115, 0.0506025 ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "mutual_info_classif(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382e633",
   "metadata": {},
   "source": [
    "- La IM de las variables irrelevantes es practicamente nula\n",
    "- La IM de las variables informativas y relevantes es similar\n",
    "\n",
    "Si utilizamos `SelectKBest` con $K=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5489d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 ms, sys: 3.03 ms, total: 30.1 ms\n",
      "Wall time: 28.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((300, 3), array(['x1', 'x2', 'x3'], dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=3)\n",
    "X_reduced = selector.fit_transform(X, y)\n",
    "X_reduced.shape, selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16231d",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "La ventaja de este método para hacer selección de características es que no depende de un modelo de clasificación en particular. Otra ventaja es que es muy eficiente computacionalmente\n",
    "\n",
    ":::\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "La desventaja de este método es que, al medir la relevancia de las características una por una, no es sensible a relaciones de redundancia y complementariedad\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e04e37",
   "metadata": {},
   "source": [
    "El problema anterior se puede aliviar utilizando un método de eliminación hacia-atras (*backward*). Scikit-learn tiene dos objetos para lograr este propósito: \n",
    "\n",
    "- [`RFE`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) (Recursive feature elimination)\n",
    "- [`SequentialFeatureSelector(direction='backward')`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector)\n",
    "\n",
    "Ambos métodos requieren de un estimador (regresor o clasificador) y se utiliza el *accuracy* en validación cruzada para hacer la selección. \n",
    "\n",
    "En particular `SequentialFeatureSelector`\n",
    "\n",
    "- Mide el accuracy utilizando todas las características menos una, para todas las características\n",
    "- Elimina la característica que produje la menor disminución en *accuracy*\n",
    "- El procedimiento se repite hasta que cumplir con un número esperado de característas especificado por el argumento `n_features_to_select`\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Este tipo de eliminación *greedy* descartará características redundates y no perderá características que son complementarias, pero tiene un gran costo en comparación a lo que vimos antes\n",
    "\n",
    ":::\n",
    "\n",
    "Por ejemplo, si pedimos tres características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48415445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 3.47 ms, total: 128 ms\n",
      "Wall time: 128 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['x0', 'x3', 'x5'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "selector = SequentialFeatureSelector(model, direction='backward', cv=3,\n",
    "                                     n_features_to_select=3)\n",
    "selector.fit(X, y)\n",
    "selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11309dc5",
   "metadata": {},
   "source": [
    "El método no entrega características redudantes entre si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265fa18",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "\n",
    "Los resultados dependen del estimador. Usar un estimador distinto puede cambiar considerablemente el resultado\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb19f3",
   "metadata": {},
   "source": [
    "### Escalamiento y normalización de características\n",
    "\n",
    "Existen dos razones importantes por las cuales es interesante escalar las características antes de entrenar un modelo\n",
    "\n",
    "1. Evitar que una variable domine a las otras sólo por tener valores más grandes\n",
    "1. Evitar inestabilidad numérica en el modelo o en el proceso de optimización del mismo]\n",
    "\n",
    "El módulo [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) de Scikit Learn proporciona clases y funciones para realizar distintos tipos de escalamiento, entre ellos\n",
    "\n",
    "- [`StandardScaler(with_mean=True, with_std=True)`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler): Equivalente a restar la media y dividir por la desviación estándar\n",
    "- [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler): Reescala la variable tal que su valor mínimo sea 0 y su valor máximo sea 1\n",
    "- [`MaxAbsScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler): Rescala la variable tal que su valor máximo sea 1 (divide por el máximo absoluto)\n",
    "- [`RobustScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler): Similar a `StandardScaler` pero utiliza estadísticos robustos ante los valores fuera de rango (outliers)\n",
    "\n",
    "Los principales métodos de estas clases son\n",
    "\n",
    "- `fit(X)`: Calcula los estadísticos de la transformación de escalamiento para `X`\n",
    "- `transform(X)` Aplica la transformación a `X`\n",
    "- `fit_transform(X)`: Equivalente a aplicar los dos pasos anteriores al mismo tiempo\n",
    "- `inverse_transform(X)`: Deshace la transformación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7381c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25250744, 0.83164766],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 0.60127725],\n",
       "       [0.2769352 , 0.27293887],\n",
       "       [0.66305614, 1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.random.randn(5, 2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226580ee",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "\n",
    "Si entrenas sobre características reescaladas debes guardar los valores de los estadísticos para poder normalizar/reescalar ejemplos futuros\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1514820b",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad\n",
    "\n",
    "Los métodos de reducción de dimensionalidad transforman un conjunto de características (numéricas) en un nuevo conjunto con un número menor de variables. Las nuevas características suelen involucrar transformaciones y combinaciones de las características originales. \n",
    "\n",
    "Existen métodos supervisados y no supervisados para reducir dimensionalidad. En este último caso no se utiliza información de la etiqueta, y se busca minimizar otro tipo de objetivo. Un ejemplo clásico y ampliamente utilizado es Análisis de Componentes Principales (*Principal Component Analysis*, PCA)\n",
    "\n",
    "Como muestra la siguiente figura, PCA aplica una transformación sobre las características originales (izquierda), creando nuevas características que son combinaciones lineales de las originales (derecha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd238fb",
   "metadata": {},
   "source": [
    "<img src=\"img/pca1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054d15d",
   "metadata": {},
   "source": [
    "El objetivo de PCA es **maximizar la varianza de las características** proyectadas en el nuevo espacio. \n",
    "\n",
    "\n",
    ":::{note}\n",
    "\n",
    "PCA produce una cantidad de características equivalente a las que se tenían originalmente\n",
    "\n",
    ":::\n",
    "\n",
    ":::{important}\n",
    "\n",
    "La reducción de dimensionalidad en PCA es manual, es decir el usuario debe decidir cuantas características preservar. Un criterio muy usado es seleccionar la cantidad de características en base a la varianza acumulada que representan\n",
    "\n",
    ":::\n",
    "\n",
    "El módulo [`decomposition`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition) de scikit-learn tiene clases y objetos para hacer reducción de dimensionalidad, entre ellos [`PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)\n",
    "\n",
    "El argumento principal de `PCA` es `n_components`, el cual puede ser un entero o un flotante en el rango [0, 1]\n",
    "\n",
    "- Si es un entero $K$ el método se quedará con las $K$ variables de mayor varianza\n",
    "- Si es un flotante $p$ el método se quedará con tantas variables como sea necesario con tal de tener un $100p\\%$  de la varianza\n",
    "\n",
    "Veamos un ejemplo con el famoso dataset [Iris](https://archive.ics.uci.edu/ml/datasets/iris):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb58005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb62f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dim_reducer = PCA(n_components=0.95)\n",
    "\n",
    "X_reduced = dim_reducer.fit_transform(X)\n",
    "\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a36cf",
   "metadata": {},
   "source": [
    "De acuerdo a los resultados, dos componentes principales son suficientes para preservar un 95% de la varianza\n",
    "\n",
    "Los datos en el espacio proyectado son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a83b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "for y_ in np.unique(y):\n",
    "    mask = y == y_\n",
    "    ax.scatter(X_reduced[mask, 0], X_reduced[mask, 1])\n",
    "ax.set_xlabel('Componente principal 1')\n",
    "ax.set_ylabel('Componente principal 2');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9ae44",
   "metadata": {},
   "source": [
    "Estos nuevas características parecen suficiente para separar las tres clases\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "PCA no utiliza la información de clases para hacer la proyección. No siempre maximizar varianza resultará en mayor separabilidad de clases\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd28ffc",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "\n",
    "PCA recibe su nombre debido a que las nuevas características y su varianza están relacionadas a los vectores y valores propios de la matriz de correlación de las características originales. Puedes profundizar sobre este tema leyendo [esta presentación](https://docs.google.com/presentation/d/1YqYy5RTB2PJ6C7syMTZCleZqyc2MJVA2APqdBAIhjBw/edit#slide=id.p)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb7664",
   "metadata": {},
   "source": [
    "## Herramientas de MLOps\n",
    "\n",
    "Un concepto que se utiliza bastante hoy en día es [Machine Learning Operations](https://docs.microsoft.com/es-es/azure/machine-learning/concept-model-management-and-deployment) (MLOPs). MLOps se refiere a la implementación de prácticas de Development Operations (DevOps) en problemas de Machine Learning, entre ellas\n",
    "\n",
    "- Integración y Entrega continuas ([CI/CD](https://www.redhat.com/en/topics/devops/what-is-ci-cd))\n",
    "- Flujos automáticos de trabajo (workflows)\n",
    "- Control de versiones (códigos pero también datos y modelos)\n",
    "- Empaquetado de soluciones\n",
    "- Orquestación de carga de inferencia\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Para hacer CI/CD con modelos de ML recomiendo [CML](https://cml.dev/)\n",
    "\n",
    ":::\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "Para administrar experimentos de Machine Learning existen herramientas de linea de comando como [`dvc exp`](https://dvc.org/doc/command-reference/exp) o dashboards como [Neptune](https://neptune.ai/product), [MLFlow](https://mlflow.org/) o [Comet](https://www.comet.ml/site/)\n",
    "\n",
    ":::\n",
    "\n",
    "MLOps está relacionado a los últimos 4 pasos del esquema MLE, estos eran\n",
    "\n",
    "**Entrega y servicio de modelos** \n",
    "\n",
    "Se refiere a cómo se entrega o sirve el modelo y/o sus predicciones al usuario, por ejemplo\n",
    "\n",
    "- Estático: El modelo es parte de un ejecutable que está instalado en la máquina del usuario\n",
    "- Dinámico (on-premise): El usuario tiene un cliente instalado en su máquina el cual solicita actualizaciones periódicas de los parámetros del modelo (cliente y modelo están separados)\n",
    "- Dinámico (cloud): El usuario sube los datos a un servidor en la nube y recibe las predicciones\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Los modelos de scikit-learn son amigables con [serialización](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html). El modelo serializado puede ser cargado por un servicio web basado en [Flask](https://flask.palletsprojects.com/en/2.1.x/) que luego el cliente accede a través de una API Rest\n",
    "\n",
    ":::\n",
    "\n",
    ":::{seealso}\n",
    "\n",
    "La herramienta [MLEM](https://mlem.ai/) de Iterative.ai facilita considerablemente el flujo anterior\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a59bed",
   "metadata": {},
   "source": [
    "**Monitoreo y mantenimiento de modelos**\n",
    "\n",
    "Se refiere a la inspección continua del desempeño del modelo en producción. Sea $X$ los datos de entrada al modelo e $Y$ la etiqueta a predecir, se define:\n",
    "\n",
    "Data drift\n",
    ": Situación en que la distribución $p(X)$ empieza a alejarse de la distribución original que se utilizó para entrenar el modelo. Esto puede deberse a que el problema es no-estacionario o a que hubo sesgo de muestreo al crear el dataset de entrenamiento\n",
    "\n",
    "Prior probability shift\n",
    ": Situación en que la distribución $p(Y)$ se aleja de la distribución original. Por ejemplo una clase deja de aparecer con tanta frecuencia y otra más originalmente más rara ocurre con mayor frecuencia. En el caso extremo podría aparecer una clase que originalmente no estaba en el dataset de entrenamiento\n",
    "\n",
    "Concept drift\n",
    ": Situación en que la distribución condicional $p(Y|X)$ cambia con respecto a la original y por lo tanto nuestro mapeo $Y=f(X)$ pierde validez. Está relacionada a situaciones externas: cambio en la interpretación de la etiqueta, aparición de una clase que no estaba considerada originalmente, pérdida de poder predictivo\n",
    "\n",
    ":::{important}\n",
    "\n",
    "Los *drift* puede identificarse comparando la distribución de los nuevos datos y predicciones con las de entrenamiento en base test estadísticos (por ejemplo Chi cuadrado o Kolmogorov-Smirov). En caso de detectar *drift*, debemos analizar las predicciones, etiquetar y reentrenar el modelo\n",
    "\n",
    ":::\n",
    "\n",
    "Adicional al desempeño, también se debe monitorear\n",
    "\n",
    "- La disponibilidad del modelo\n",
    "- La estabilidad numérica del modelo\n",
    "- El consumo de recursos de hardware del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5d9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
