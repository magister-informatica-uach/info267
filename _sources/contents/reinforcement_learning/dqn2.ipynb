{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN a partir de píxeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *gym* de OpenAI tiene una colección de juegos de ATARI 2600 que pueden usarse como benchmark\n",
    "\n",
    "La mayoría tiene una versión normal y una versión RAM\n",
    "\n",
    "- En la versión normal las observaciones son imágenes de 260x120x3\n",
    "- En la versión RAM las observaciones son 128 bits que corresponden a la memoria de la consola\n",
    "\n",
    "En este ejemplo nos concentraremos en la versión normal y usaremos redes convolucionales para resolverlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Las acciones de este ambiente:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'La dimensión del estado:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAF2CAYAAAAhli5UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHXElEQVR4nO3dzY4cVxmA4VM9PXH8IxuDFAEmG8sRBnYgLgDYwIY74Aq4BK6ALTvWSLBCbLkIEiSCWCIiEiKE7MiKf2J7uooFSCA8TtpDj9/x9PNIs+mqPvp6NHo1dbrVNS3LsgyAyKoeANhvIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUuttT3zr9rUXXvyt21fHra+++PPOgouH6/HFz13a2XqbeR4ffPRgbGYfUH/VLcv1Mc/fGGNMO1rxyVit3hnT9HRH650dP/vpHz/znK0j9P0ffuX/GuZV84Urr4/vfX13r/nhk6Pxm7f/PB49OdrZmjTm5eZ4evSTsbsI3R0XXvvxGOOjHa33atk6QtO0q1/4q2VfXzfb8LexC/aEgJQIASkRAlIiBKS23pjmP/569/744O79Zx6fpjFuf+n6uHbpQjAVZ8Fq+t1Yrd455sg0NvMPxrLs17vM2xChE/j7vYfj3ffvHHvsxvUrIrTHVqs/jfX61888vizTmOdvjWWI0P9yOQakRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEj5etcTuHbptfHm56888/g0jfH64UEwEWfFvNwYm823jzmyGsu4+tLneRWI0AnceuPauPXGtXoMzqB5/u6Y5+8cc8TdWp9HhE7AraF5vmkIzouxJwSkRAhIiRCQEiEgZWP6Oe49ejze/ss/drbe0808nh7NO1uPzjT9bawPfjF2twH96N8/+0mEnuPjT56O37+3uwhxfqymD8dq/ct6jHPD5RiQEiEgJUJAaus9oQ8f7O/GGXB6to7Qe/cfnuYcwJ5yOQakRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIAamtv0/ozSuXTnMOYE9tHaEbly+e5hzAnnI5BqRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUlt/qdl/2yzLWJZljDHGNKaxmsaYpmmngwH74UQRev/+w3H38ZMxxhhXDw/HzauXdzoUsD9OFKGjeRmPN/MYY4wnB/NOBwL2iz0hICVCQEqEgJQIAakTbUxfOFiNK+t/PfXi+mCnAwH75UQRunH54viymyECO3CiCE3TNHw0EdgFe0JASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUut6AGC3luWzz5mm059jWyIE5840jjY/Gsty85hjH4/D9c/HGPdf9lDPJUJwDi3z18a8fPOYI3fGGIcve5xPZU8ISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpNz8EM6tLe4HfQaIEJw7yzhY/2ocLL895tjjMcaDlz3QpxIhOGemaYyD6Q/1GFuzJwSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlLrbU/8ZLM5zTmAPbV1hN69c+805wD21NYR2izLac4B7Cl7QkBKhICUCAEpEQJSIgSkRAhIiRCQEiEgJUJASoSAlAgBKRECUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlIiBKRECEiJEJASISAlQkBqWha3VgU6/hMCUiIEpEQISIkQkBIhICVCQEqEgJQIASkRAlL/BOUhoKE5/ZoHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 300x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "env_name = \"PongNoFrameskip-v4\"\n",
    "#env_name =\"BreakoutNoFrameskip-v4\"\n",
    "#env_name = \"SpaceInvadersNoFrameskip-v4\"\n",
    "\n",
    "env = gym.make(env_name)\n",
    "state, _ = env.reset()\n",
    "\n",
    "display(\"Las acciones de este ambiente:\", env.unwrapped.get_action_meanings())\n",
    "display(\"La dimensión del estado:\", state.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 4), tight_layout=True)\n",
    "ax.axis('off')\n",
    "ax.imshow(state);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estado es una imagen de 210 x 160 x 3 pixeles\n",
    "\n",
    "Para facilitar el entrenamiento se recomienda hacer un preprocesamiento como el que sigue\n",
    "\n",
    "1. (opcional) Descartar parte de la imagen que no aporta información\n",
    "1. Reescalar la imagen a un menor tamaño\n",
    "1. Combinar los canales y generar una imagen de escala de grises\n",
    "1. Crear un stack de cuatro frames como representación del estado\n",
    "1. Convertir los pixeles a float y normalizar al rango [0, 1]\n",
    "\n",
    "Para esto usaremos la librería *torchvision* y los *wrappers* de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del tensor transformado: (torch.Size([4, 84, 84]), torch.float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from gymnasium.wrappers import AtariPreprocessing, FrameStack\n",
    "\n",
    "def wrap_env(env, skip=4, k=4):\n",
    "    env = EpisodicLifeEnv(env) # Perder una vida es equivalente a perder el episodio\n",
    "    env = FireResetEnv(env) # Hace un disparo al inicio (algunos juegos lo necesitan)\n",
    "    env = WarpFrame(env) # Crop, resize y conversión a escala de  grises\n",
    "    env = ClipRewardEnv(env) # La recompensa se corta en [-1, 1] (mejora la estabilidad)\n",
    "    env = FrameStack(env, k=k) # El ambiente entrega de a 4 frames    \n",
    "    return env\n",
    "\n",
    "env = FrameStack(AtariPreprocessing(gym.make(env_name), \n",
    "                                    noop_max=30, \n",
    "                                    frame_skip=4, \n",
    "                                    screen_size=84, \n",
    "                                    terminal_on_life_loss=False), num_stack=4)\n",
    "env.reset()\n",
    "state, _, _, _, _ = env.step(2)\n",
    "\n",
    "def transform_state(state):\n",
    "    return torch.from_numpy(np.array(state).astype('float32'))\n",
    "\n",
    "transformed_state = transform_state(state)\n",
    "print(f\"Tamaño del tensor transformado: {transformed_state.shape, transformed_state.dtype}\")\n",
    "fig, ax = plt.subplots(1, 4, figsize=(8, 5), tight_layout=True)\n",
    "for k in range(4):\n",
    "    ax[k].matshow(transformed_state[k, :, :].numpy(), cmap=plt.cm.Greys_r);\n",
    "    ax[k].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Red convolucional para estimar la función Q**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(torch.nn.Module):    \n",
    "    def __init__(self, n_input, n_output, n_filters=32, n_hidden=256):\n",
    "        super(type(self), self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(n_input, n_filters, kernel_size=8, stride=4)\n",
    "        self.conv2 = torch.nn.Conv2d(n_filters, n_filters, kernel_size=4, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1)\n",
    "        self.linear1 = torch.nn.Linear(7 * 7 * n_filters, n_hidden)\n",
    "        self.output = torch.nn.Linear(n_hidden, n_output)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.conv1(x))\n",
    "        h = self.activation(self.conv2(h))\n",
    "        h = self.activation(self.conv3(h))\n",
    "        h = h.view(-1, 7*7*32)\n",
    "        h = self.activation(self.linear1(h))\n",
    "        return  self.output(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replay Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, state_dim, memory_length=2000): \n",
    "        self.length = memory_length\n",
    "        self.pointer = 0\n",
    "        self.filled = False\n",
    "        # Tensores vacíos para la historia\n",
    "        self.s_current = torch.zeros((memory_length,) + state_dim)\n",
    "        self.s_future = torch.zeros((memory_length,) + state_dim)\n",
    "        self.a = torch.zeros(memory_length, 1, dtype=int)\n",
    "        self.r = torch.zeros(memory_length, 1)\n",
    "        # Adicionalmente guardaremos la condición de término\n",
    "        self.end = torch.zeros(memory_length, 1, dtype=bool)\n",
    "    \n",
    "    def push(self, s_current, s_future, a, r, end):\n",
    "        # Agregamos una tupla en la memoria\n",
    "        self.s_current[self.pointer] = s_current\n",
    "        self.s_future[self.pointer] = s_future\n",
    "        self.a[self.pointer] = a\n",
    "        self.r[self.pointer] = r \n",
    "        self.end[self.pointer] = end\n",
    "        if self.pointer + 1 == self.length:\n",
    "            self.filled = True\n",
    "        self.pointer =  (self.pointer + 1) % self.length\n",
    "        \n",
    "    def sample(self, size=64):        \n",
    "        # Extraemos una muestra aleatoria de la memoria\n",
    "        if self.filled:\n",
    "            idx = np.random.choice(self.length, size)\n",
    "        elif self.pointer > size:\n",
    "            idx = np.random.choice(self.pointer, size)\n",
    "        else:\n",
    "            return None        \n",
    "        return self.s_current[idx], self.s_future[idx], self.a[idx], self.r[idx], self.end[idx]    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente DQN\n",
    "\n",
    "Detalles prácticos a considerar\n",
    "\n",
    "- **Huber Loss:** Combinación del error cuadrático y el error absoluto. Se usa el error cuadrático para errores pequeños y el error absoluto para errores grandes. Mejora la estabilidad numérica del algoritmo\n",
    "- **Gradient clipping:** Limitar el gradiente en un rango [mínimo, máximo], usualmente $[0,1]$. También se puede limitar dividiendo por la norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "    \n",
    "class DeepQNetwork:\n",
    "    def __init__(self, q_model, gamma=0.99, double_dqn=False, learning_rate=1e-3, \n",
    "                 target_update_freq=500, clip_grads=True, clip_error=False, huber=False):\n",
    "        self.double_dqn = double_dqn\n",
    "        self.gamma = gamma\n",
    "        self.q_policy = q_model\n",
    "        self.n_output = q_model.output.out_features\n",
    "        self.clip_error = clip_error\n",
    "        self.clip_grads = clip_grads\n",
    "        self.update_counter = 0\n",
    "        self.target_update_freq = target_update_freq\n",
    "        if not huber:\n",
    "            self.criterion = torch.nn.MSELoss()\n",
    "        else:\n",
    "            self.criterion = torch.nn.SmoothL1Loss()\n",
    "        self.optimizer = torch.optim.RMSprop(self.q_policy.parameters(), lr=learning_rate)\n",
    "        \n",
    "        if double_dqn:\n",
    "            self.q_target = copy.deepcopy(self.q_policy)\n",
    "            self.q_target.eval()\n",
    "    \n",
    "    def select_action(self, state, epsilon=0.):\n",
    "        # Estrategia epsilon greedy para seleccionar acción\n",
    "        if torch.rand(1).item() < 1. - epsilon: \n",
    "            self.q_policy.eval()\n",
    "            with torch.no_grad():\n",
    "                q = self.q_policy(state)[0]\n",
    "                a = q.argmax().item()\n",
    "                q = q[a]\n",
    "            self.q_policy.train()\n",
    "        else:\n",
    "            q = None\n",
    "            a = torch.randint(high=self.n_output, size=(1,)).item() \n",
    "        \n",
    "        return a, q\n",
    "    \n",
    "    def update(self, mini_batch):\n",
    "        self.update_counter += 1\n",
    "        state, state_next, action, reward, end = mini_batch\n",
    "        # Calcular Q\n",
    "        q_current = self.q_policy(state).gather(1, action)\n",
    "        with torch.no_grad():\n",
    "            if not self.double_dqn:\n",
    "                q_next_best = self.q_policy(state_next).max(1, keepdim=True)[0]\n",
    "            else:\n",
    "                action_next = self.q_policy(state_next).argmax(dim=1, keepdim=True)\n",
    "                q_next_best = self.q_target(state_next).gather(1, action_next)               \n",
    "        # Construir el target: r + gamma*max Q(s', a')\n",
    "        td_target = reward\n",
    "        td_target[~end] += self.gamma*q_next_best[~end]\n",
    "        td_target[end] = -1.\n",
    "        # Calcular pérdido y sus gradientes\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(q_current, td_target)\n",
    "        if self.clip_error:\n",
    "            loss.clamp_(-1., 1.)\n",
    "        loss.backward()\n",
    "        # Cortar gradientes grandes (mejora la estabilidad)\n",
    "        if self.clip_grads:\n",
    "            for param in self.q_policy.parameters():\n",
    "                param.grad.data.clamp_(-1., 1.)\n",
    "            #torch.nn.utils.clip_grad.clip_grad_norm_(self.q_policy.parameters(), 10)\n",
    "        # Actualizar\n",
    "        self.optimizer.step()\n",
    "        # Transfer policy to target\n",
    "        self.transfer_policy2target()\n",
    "        # Retornar el valor de la loss\n",
    "        return loss.item()\n",
    "    \n",
    "    def transfer_policy2target(self):\n",
    "        if self.double_dqn:            \n",
    "            if self.update_counter % self.target_update_freq == 0:\n",
    "                self.q_target.load_state_dict(self.q_policy.state_dict())\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "\n",
    "fig, ax = plt.subplots(4, figsize=(6, 5), sharex=True, tight_layout=True)\n",
    "\n",
    "def smooth_data(x, window_length=10):\n",
    "    return convolve(x, np.ones(window_length)/window_length, mode='valid')\n",
    "\n",
    "def update_plot(step, episode, smooth_window=10, target=None):\n",
    "    for ax_ in ax:\n",
    "        ax_.cla()\n",
    "    episodes = np.arange((episode))\n",
    "    ax[0].scatter(episodes, diagnostics['rewards'], s=1)      \n",
    "    if episode > smooth_window:\n",
    "        ax[0].plot(episodes[:-smooth_window+1], \n",
    "                   smooth_data(diagnostics['rewards']), alpha=0.5, lw=2)        \n",
    "    ax[1].plot(episodes, diagnostics['loss'])\n",
    "    ax[2].plot(episodes, np.array(diagnostics['q_sum'])/(np.array(diagnostics['q_N'])+1e-4))\n",
    "    if not target is None:               \n",
    "        ax[0].plot(episodes, [target]*len(episodes), 'k--')\n",
    "    ax[0].set_ylabel('Recompensa');\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[2].set_ylabel('Q promedio')\n",
    "    ax[3].plot(episodes, epsilon(episodes))\n",
    "    ax[3].set_ylabel('Epsilon')\n",
    "    ax[3].set_xlabel('Episodios')\n",
    "    ax[0].set_title(\"Paso %d\" % (step))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a83882bbc794524aeef39dff4052437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m stacked_states, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)):    \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Escoger acción\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     a, q \u001b[38;5;241m=\u001b[39m dqn_model\u001b[38;5;241m.\u001b[39mselect_action(state\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), epsilon(episode))\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[47], line 22\u001b[0m, in \u001b[0;36mtransform_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_state\u001b[39m(state):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "n_state = (4, 84, 84)\n",
    "n_action = env.action_space.n \n",
    "\n",
    "dqn_model = DeepQNetwork(q_model=ConvolutionalNeuralNetwork(n_state[0], n_action),\n",
    "                         gamma = 0.99,\n",
    "                         double_dqn=True,\n",
    "                         target_update_freq=1000,\n",
    "                         learning_rate=1e-4, huber=True)\n",
    "\n",
    "def epsilon(episode, epsilon_init=0.1, epsilon_end=0.01, epsilon_rate=1e-2):\n",
    "    return epsilon_end + (epsilon_init - epsilon_end) * np.exp(-epsilon_rate*episode) \n",
    "\n",
    "memory = ReplayMemory(n_state, memory_length=10000)        \n",
    "\n",
    "diagnostics = {'rewards': [0], 'loss': [0],\n",
    "               'q_sum': [0], 'q_N': [0]}\n",
    "\n",
    "episode = 1\n",
    "terminated, truncated = False, False\n",
    "stacked_states, _ = env.reset()\n",
    "\n",
    "for step in tqdm(range(100000)):    \n",
    "    # Escoger acción\n",
    "    state = transform_state(stacked_states)\n",
    "    a, q = dqn_model.select_action(state.unsqueeze(0), epsilon(episode))\n",
    "    if q is not None:\n",
    "        diagnostics['q_sum'][-1] += q\n",
    "        diagnostics['q_N'][-1] += 1\n",
    "    \n",
    "    # Aplicar la acción \n",
    "    stacked_states_next, r, terminated, truncated, info = env.step(a)  \n",
    "    diagnostics['rewards'][-1] += r\n",
    "    # Guardar en memoria\n",
    "    memory.push(state, transform_state(stacked_states_next), \n",
    "                a, torch.tensor(r), terminated)\n",
    "    \n",
    "    stacked_states = stacked_states_next\n",
    "    \n",
    "    # Actualizar modelo    \n",
    "    mini_batch = memory.sample(32)\n",
    "    if not mini_batch is None:\n",
    "        diagnostics['loss'][-1] += dqn_model.update(mini_batch)            \n",
    "    \n",
    "    # Preparar siguiente episodio\n",
    "    if terminated or truncated:\n",
    "        if episode % 5 == 0:\n",
    "            update_plot(step, episode)\n",
    "        episode += 1   \n",
    "        terminated = False\n",
    "        stacked_states, _ = env.reset()\n",
    "        diagnostics['rewards'].append(0)\n",
    "        diagnostics['loss'].append(0)\n",
    "        diagnostics['q_sum'].append(0)\n",
    "        diagnostics['q_N'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If mode is 'interp', window_length must be less than or equal to the size of x.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax_, (key, val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ax, diagnostics\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      5\u001b[0m     ax_\u001b[38;5;241m.\u001b[39mplot(val, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     ax_\u001b[38;5;241m.\u001b[39mplot(\u001b[43msavgol_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     ax_\u001b[38;5;241m.\u001b[39mset_ylabel(key)\n\u001b[1;32m      8\u001b[0m ax_\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "File \u001b[0;32m~/.conda/envs/info147/lib/python3.9/site-packages/scipy/signal/_savitzky_golay.py:345\u001b[0m, in \u001b[0;36msavgol_filter\u001b[0;34m(x, window_length, polyorder, deriv, delta, axis, mode, cval)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m window_length \u001b[38;5;241m>\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[axis]:\n\u001b[0;32m--> 345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf mode is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, window_length must be less \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan or equal to the size of x.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# Do not pad. Instead, for the elements within `window_length // 2`\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# of the ends of the sequence, use the polynomial that is fitted to\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# the last `window_length` elements.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     y \u001b[38;5;241m=\u001b[39m convolve1d(x, coeffs, axis\u001b[38;5;241m=\u001b[39maxis, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: If mode is 'interp', window_length must be less than or equal to the size of x."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(7, 5), sharex=True)\n",
    "for ax_, (key, val) in zip(ax, diagnostics.items()):\n",
    "    ax_.plot(val, alpha=0.5, c='b')\n",
    "    ax_.plot(savgol_filter(val, 50, 1), c='b')\n",
    "    ax_.set_ylabel(key)\n",
    "ax_.set_xlabel('Episode');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el agente para futura referencia y evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gymnasium.wrappers.frame_stack.LazyFrames at 0x7fb08fb90720>,\n",
       " {'lives': 0, 'episode_frame_number': 13, 'frame_number': 3932})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"mi_modelo.pkl\", \"wb\") as f:\n",
    "    pickle.dump([dqn_model, dqn_model.q_policy.state_dict()], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import sleep\n",
    "\n",
    "env = wrap_env(gym.make(env_name), skip=1)\n",
    "stacked_states = env.reset()\n",
    "end = False\n",
    "\n",
    "while not end:\n",
    "    state = preprocess(stacked_states)\n",
    "    a, q = dqn_model.select_action(state.unsqueeze(0))\n",
    "    stacked_states, r, end, info = env.step(a)\n",
    "    env.render() \n",
    "    sleep(.01)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentes artesanales pre-entrenados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Estos agentes corresponden a la última iteración, \n",
    "# pero en realidad debería grabarse el que obtiene mejor recompensa \n",
    "\n",
    "# Pong entrenado durante 200_000 pasos con memoria de 10_000, aprox 2hrs de entrenamiento\n",
    "env_name = \"PongNoFrameskip-v4\"\n",
    "with open(\"modelos/pong_masomenos.pkl\", \"rb\") as f:\n",
    "    dqn_model_loaded, q_policy_state_dict_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import sleep\n",
    "\n",
    "random_agent = False\n",
    "env = wrap_env(gym.make(env_name), skip=1)\n",
    "stacked_states = env.reset()\n",
    "end = False\n",
    "\n",
    "while not end:\n",
    "    if not random_agent:\n",
    "        state = preprocess(stacked_states)\n",
    "        a, q = dqn_model_loaded.select_action(state.unsqueeze(0))\n",
    "    else:\n",
    "        a = env.action_space.sample()\n",
    "    stacked_states, r, end, info = env.step(a)\n",
    "    env.render() \n",
    "    sleep(.01)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
